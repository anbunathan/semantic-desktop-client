,0
0,Improving Text Retrieval Efficiency with Pattern Structures on Parse Thicketsr
1,Learning Parse Structure of Paragraphs and its Applications in Searchr
2,We propose to combine parse forest and discourse structures to form a unified representation for a paragraph of text   The purpose of this representation is to tackle answering complex paragraphsized questions in a number of products and servicesrelated domains A candidate set of answers obtained by a keyword search is reranked by matching the sequence of parse trees of an answer with that of the question To do that a graph representation and learning technique for parse structures for paragraphs of text have been developed Parse Thicket PT as a set of syntactic parse trees augmented by a number of arcs for intersentence wordword relations such as coreference and taxonomic relations is introduced These arcs are also derived from other sources including Speech Act and Rhetoric Structure theories The operation of generalization of logical formulas is extended towards parse trees and then towards parse thickets to compute similarity between texts r
3,We provide a detailed illustration of how PTs are built from parse trees and generalized The proposed approach is subject to evaluation in the product search and recommendation domain of eBaycom where user queries include product names desired features and expressions for user needs in multiple sentences We demonstrate that search relevance is improved by PT generalization using Bing search engine API as a baseline We perform the comparative analysis of contribution of various sources of discourse information to the relevance An open source plugin for SOLR is developed so that the proposed technology can be easily integrated with industrial search enginesr
4,Keywords Parse Forest Parse Thicket Graph Learningr
5,Parse trees were found fairly useful in solving text classification and text relevance problems including search Parse trees have become a standard form of representing the syntactic structures of sentences Abney  Punyakanok et al  A number of approaches to learning parse trees have been proposed including convolution kernel based on support vector SVM learning Collins and Duffy  Haussler   Moschitti  and structural similarity based on direct matching of parse trees for sentences Galitsky et al  r
6,As to the structure of a paragraph of text there is no generally accepted model Such a model needs to rely on the parse forest for the sentences this paragraph comprises and also need to include a paragraphlevel discourse information  HowIn this study we will attempt to represent a linguistic structure of a paragraph of text based on parse trees for each sentence of this paragraph We will refer to the sequence of parse trees plus a number of arcs for intersentence relations of the discourse type between the nodes for words as Parse Thicket PT A PT is a graph which includes parse trees for each sentence as well as additional arcs for intersentence relationship Parse thickets are inspired by the problem of answering complex paragraphsize questions which needs to be matched with paragraphs of candidate answersr
7,We explore a number of sources for the links between words in a paragraph other than syntactic Our sources are coreferences entityentity and other taxonomic relations discourse relations such as rhetoric relations between elementary discourse units and speech act relations For each of these sources we determine whether it can be leveraged by more accurate assessment of similarity between paragraphs of text The main goal here is to make similarity measure independent of how text  phrases is distributed through sentencesr
8,A vast majority of linguistic theories from cognitive to functional theories of grammars rely on need some form of representation of structured data for natural language processing Lamberti et al  Once a linguistic representation becomes richer than the bagofwords there is a need for a systematic way to compare such representations However there is a lack of formal models to compare linguistic structures beyond parse trees for individual sentences In this study we introduce PTs as a structural machine learning framework to operate with multiple syntactic parse trees for sentences in paragraphs of text r
9,Nowadays commercial search engines are not very good at tackling paragraphlevel queries consisting of multiple sentences They either find very similar documents if they are available or very dissimilar ones so that search results are not very useful to the user This is due to the fact that for multisentences queries it is rather hard to learn ranking based on user clicks since the number of longer queries is practically unlimited Hence we need a linguistic technology which would rank candidate answers based on structural similarity between the question and the answer In this study we build a graphbased representation for a paragraph of text so that we can track the structural difference between these paragraphs taking into account not only parse trees but the whole discourse of both the question and answers r
10,The demand for access to different types of information have led to a renewed interest in answering questions posed in ordinary human language and seeking  exact specific and complete answer After having made substantial achievements in factfinding and list questions natural language processing NLP community turned their attention to more complex information needs that cannot be answered by simply extracting named entities persons organization locations dates etc from single sentences in documents Chali et al  Unlike simple factoid questions complex questions often seek multiple different types of information simultaneously located in multiple sentences and one cannot assume that a particular single sentence contains expected information Dependency parsing helps to answer complex queries in an industrial environment reconstructing semantic content efficiently by extracting related terms through analysis and classification Iwashita et al  To systematically analyze how keywords from a query occur in multiple sentences in a document one needs to explore coreferences and other relations between words within a sentence and between sentencesr
11,Most search engines attempt to find the occurrence of query keywords in a single sentence in a candidate search result Kim et al  If it is not possible or has a low search engine score multiple sentences within one document are used However modern search engines have no means to determine if the found occurrences of the query keywords in multiple sentences are related to each other or not Neither search engine can determine if they are related to the same entity nor being in different sentences are all related to the query termr
12,Paragraphs of text as queries appear in the searchbased recommendation domains Montaner et al  Bhasker and Srikumar  Thorsten  Recommendation agents track user chats user postings on blogs and forums user comments on shopping sites and suggest web documents and their snippets relevant to a purchase decisions To do that these recommendation agents need to take portions of text produce a search engine query run it against a search engine API such as Bing or Yahoo and filter out the search results which are determined to be irrelevant to a purchase decision The last step is critical for a sensible functionality of a recommendation agent and poor relevance would lead to a lost trust in the recommendation engine Hence an accurate assessment of similarity between two portions of text is critical to a successful use of recommendation agentsr
13,Nowadays the problem of answering simple queries involving a single entity and its attributes is solved fairly well However more complex questions in such domain as legal science and health can be expressed in paragraphs rather than in single phrases or single sentences as expressed for example in Yahoo Answers or StackOverflow The technique being proposed targets the paragraphsized questions which involve multiple entities and their interconnected attributes These attributes do not occur altogether but instead follow a certain discourse which needs to be extracted from the question and then matched with the ones from candidate answers For example to answer the following question we do not just need to match the keywords from actual questions two last sentences but also match the preceding sentences with that of a candidate answerr
14,One of the provisions in the Patient Protection and Affordable Care Act  is that it limits the profits of health insurance companies The ACA imposes a minimum medical loss ratio MLR on all insurers The MLR is the amount of money spent on covered person medical care divided by the total revenue received through premiums What constitutes ‘medical care’ Do investments in electronic health records count as medical care r
15,If a question includes just a phrase or a sentence selecting less frequent keywords to match with candidate answers do the job However in this case one needs to track how entities like ‘medical care’ are introduced and how the links between their attributes are established To match this paragraphsized question with an answer one needs to build a representation of its discourse on one hand PT and also provide a machinery to match this discourse structure with that of a candidate answer PT generalization r
16,Fig A high level view of the contribution of this paper we ascend from the level of individual sentences on the top to the level of paragraphs on the bottom     r
17,In this study we attempt to systematically extract semantic features from paragraphs of text using a graphbased learning assuming that adequate parsing trees for individual sentences are available In our earlier studies Galitsky et al  Galitsky et al  we applied graph learning to parse trees at the sentence level and here we proceed to learning the structure of paragraphs relying on parse forest We have defined the least general generalization of parse trees we call it syntactic generalization and in this study we extend it to the level of paragraphs We have applied generalizations of parse trees to the cases where a query is based on a single sentence and candidate answers consist from single sentences  Galitsky et al  and multiple sentences Galitsky et al  In these cases to rerank answers we needed pairwise sentencesentence generalization and sentenceparagraph generalizations respectively In this study we rely on PT to perform a paragraphlevel generalization where both questions and answers are paragraphs of textr
18,The contribution of this paper is to ascend from sentencelevel generalization to paragraphlevel generalization Fig On the top the common part of two parse trees is shown which is a generalization of two sentences On the bottom we show a number of mapped subgraphs which form the common parts of two PTs graphs which is a generalization of two paragraphs Generalizing paragraphs of text we do not only have to match words and their syntactic links but their discourse relations as well Hence overall generalization structure is much more difficult than in the case of individual sentences r
19,The chart for how generalization of parse thickets supports search relevance is shown in Fig  The PT generalization system inputs a search query and candidate answers obtained from local search index or using Bing search engine API PT is computed for the query which is a paragraph of text and each candidate answer Then each answer is generalized with the query to obtain the similarity score which is the basis for relevance assessment As a result the answers with high similarity score is outputted as relevant r
20,We define the operation of generalization of text paragraphs via generalization of respective PTs to assess similarity between them The use of generalization for similarity assessment is inspired by structured approaches to machine learning versus unstructured statistical alternatives where similarity is measured by a distance in feature space Our intention is to extend the operation of least general generalization eg the antiunification of logical formulas towards structural representations of paragraph of texts Hence we will define the operation of generalization on a pair of PT as finding the maximal common subthickets and outline two approaches to itr
21,•Based on generalizing phrases from two paragraphs of textr
22,•Based on generalizing graph representation for PTs for these paragraphsr
23,To represent the structure of a paragraph of text given parse trees of its sentences we introduce the notion of Parse Thicket PT as a sequence of parse treesr
24,Fig  Illustration for the main contribution of this paperr
25,Rhetoric Structures and Speech Acts as intersentence linksr
26,In this section we attempt to treat computationally with a unified framework two approaches to textual discourser
27,We selected these theories as most reliable and frequent sources of links between sentences Although both these theories have psychological observation as foundations and are mostly of a noncomputational nature we will build a specific computational framework for them For RST we will use explicit rules which will be applied to each sentence attempt to extract an RST relation and add a link to the PT For SpActT we use a vocabulary of communicative actions to find their subjects and add respective links to PT In this section we provide the background for these theories of discourse and explain how to use them to build links between sentence building parse thickets In Section we will show how to use these PT arcs for generalization operationr
28,People sometimes assume that whenever a text has some particular kind of discourse structure there will be a signal indicating that structure A typical case would be a conjunction such as ‘but’ What structure is seen depends vitally on the words and sentences of the text are but the relationship between words and text structure is extremely complex Phrases and syntactic patterns can also be used to signal discourse structure r
29,When one searches for document as an answer to a question it can reside in multiple portions in this document To link these portions automatically one needs to link these portions somehow and RST relation can be leveraged Searching for a review on “white iPhone case it can read r
30,“ I got a case for my iPhone … Sentence … Sentence … But when I got white case …r
31,Here conjunction But indicates the connection between the First sentence and Fourth sentence which happen to contain the phrase which matches white iPhone case Notice that not all sentences containing keywords we seek can be matched if there is no corresponding discourse relation white can refer to another object not iPhone caser
32,RST was originally developed as part of studies of computerbased text generation at Information Sciences Institute in by Bill Mann Sandy Thompson and Christian Matthiessen The theory is designed to explain the coherence of texts seen as a kind of function linking parts of a text to each other which is employed in building PTs This coherence is explained by assigning a structure to the text which slightly resembles a conventional sentence structure We adjust this structure for the purpose of multisentence search abilityr
33,Text parsing using RST has also been attempted although not as enthusiastically Marcu  presented an algorithm to parse the discourse structure of texts using discourse markers as indicators of relations Corston and Oliver  included other sources of information whether the span in question is a main coordinate or subordinate clause; position of clause main subordinate or subordinatemain; presence of certain adverbs; presence of pronouns; polarity of the clause etc Le and Abeysinghe  combine discourse markers syntactic relations and cohesive devices Schilder  uses discourse markers and position to parse discourse structure of a slightly different form using Segmented Discourse Representation Theory Asher and Lascarides  r
34,We now introduce the relations of RST Discourse units are clauses with verbs and its obligatory arguments sentences titles and section titles even when they are verbless Both restrictive and nonrestrictive modifiers that use a finite verb are embedded units Adjacent text spans are linked together via rhetorical coherence relations Mononuclear relations hold between text spans where one of them the nucleus is more salient to the discourse structure and the other one the satellite represents supporting information If you show them this movie  they’ll screamr
35,Multinuclear hold between or more text spans each of which has the same weight in the discourse structure Go to url Find menu item register Type your namer
36,Mononuclear relation links nucleus with its satellite As an answer satellite is only valid as long as satellite is present r
37,We now introduce the rules to extract RST relations between elementary discourse units in the following formr
38,where Syntactic template indicates how to extract a particular RST relation from text andr
39,is a set of  phrases which will be linked Partof Syntactic template is a set of sublists of Syntactic template phrasesr
40,For the purpose of building PT we construct syntactic templates to express RST Relational classes We don’t have to cover all RST relation and we don’t have to be precise in establishing them unless relation type is matched with query term We enumerate the relations and give example of some templates we use to detect an RST links and specify respective linking rulesr
41,Once rhetoric relation in one text is found it can be generalized with this relation in another text We propose a definition to do that which will be the part of overall PT generalizationr
42,iRST relations in text  jRST relations in text Notice that individual RST generalization will be defined in Section r
43,Adapting Speech Act Theory for multisentence searchr
44,In this section we formulate the Theory of Speech Act in a way applicable to finding links between sentences for paragraphlevel generalization In this theory dialogue negotiation conflict dispute are forms of interactions between human agents Elements of the language which expresses these interactions are referred to as locutions speech acts Bach & Harnish  utterances or communicative actions we are going to keep using the last term and use abbreviation CAr
45,How can CAs serve as links between sentences and help answer questions For the same question we used in the previous Section white iPhone case let us consider a document “I asked them about cases for iPhone … I needed it to protect my phone … Sentence … Sentence  They answered that they had a white case What is important here is the link between CA asks and CA answered passing through multiple sentences The fact that the latter CA is a reaction response to the former is a basis for our conclusion that the subjects of these CAs  cases for iPhone had a white case  are correlated Hence the phrases expressing these subjects can be linked and matched together against a question To determine that CAis a reaction to CA we need to establish their attributes leveraging Speech Act Theoryr
46,Definition   A communicative action is a functor of the formr
47,where verb characterizes some kind of interaction between people eg explain confirm remind disagree deny etc agent identifies the person  and subject refers to the information transmitted or object described and cause refers to the motivation or explanation for the subjectr
48,The foundation of the current theory of Speech Acts was developed by Austin  where  he explores the performative utterances aiming to prove that when people speak they are doing more than simply conveying information—they act A speech act is essentially a theory that asserts the claim that in saying something we perform something It is an action that is performed by means of language An example would be a performative act of a judge during a hearing when he says “I now pronounce that the case is solved  Due to Austin’s designation of speech acts sentences like this adopt a notion of action The judge’s sentence is not a report of the action; it is the action indeed Austin distinguishes between three types of linguistic acts the act of saying something what one does in saying it and what one does by saying it He labels them Locutionary  Illocutionary and Perlocutionary respectively Farrell  A locutionary act is simply saying something about the world eg a declarative sentence such as “The product does not work This sentence is not posing a question promising or commanding anything It simply states something about the world containing purely propositional content This type of act is the most basic and does not require much more explanationr
49,The illocutionary act includes promising questioning admitting hypothesizing etc The locutionary act was simply the act of saying something while the illocutionary act is performed in saying something For example “A company promises to support the product after it is sold asserts more than simply stating a sentence about the world It includes an assertion that is performative in nature Illocutionary acts are very prominent in language and are frequently in use in complaint scenarios  The third type of linguistic acts are perlocutionary ones These are nonconventional sentences that cause a natural condition or state in a person These acts deemphasize the actual intentions and focus on the effects on the hearer For example acts of frightening or convincing depend on the response of another person If a perlocutionary act is successful then one can state that an illocutionary acts has successfully taken placer
50,Approximating scenarios of multiagent interactions we follow along the lines of communicative actions’ division into constatives and performatives  r
51,· Constatives describe or report some state of affairs such that it is possible to assess whether they are false or truer
52,· Performatives on the other hand are fortunate or unfortunate sincere or insincere realistic or unrealistic and finally valid or invalid which is the focus of the current study Performatives address the attitude of an the agent performing the linguistic act including his thoughts feelings and intentionsr
53,To choose communicative actions to adequately represent an interaction between humans we have selected the most frequently used ones from our structured database of complaints Table  Galitsky et al   r
54,Agree explain suggest remind allow try request understand inform confirm ask check ignore convince disagree appeal deny threaten bring to customer’s attention accept complaint accept deny responsibilities encourage cheatr
55,A number of computational approaches have attempted to discover and categorize how the agents’ attitudes and communicative actions are related to each other in the case of computational simulation of human agents Searle  Cohen & Levesque  Applying machine learning to the attitudes and communicative actions we are primarily concerned with how these approaches can provide a unified and robust framework for computing similarity between the communicative actions The theory of speech acts seems to be one of the most promising approaches to categorizing communicative actions in terms of their roles Following Bach & Harnish  we consider four categories of illocutionary communicative actions with major representatives stating requesting promising and apologizing Each speech act is related to a single category only in the framework of the speech act theory r
56,To extend the speech act–based means of expressing similarity between communicative actions we introduce five attributes each of which reflects a particular semantic parameter for communicative activityr
57,· Positive negative attitude expresses whether a communicative action is a cooperative friendly helpful move  uncooperative unfriendly unhelpful move  neither or both hard to tell r
58,· Request  respond mode specifies whether a communicative action is expected to be followed by a reaction  constitutes a response follows a previous request neither or both hard to tell r
59,· Info supply  no info supply tells if a communicative action brings in an additional data about the conflict  does not bring any information   does not occur herer
60,· High  low confidence specifies the confidence of the preceding mental state so that a particular communicative action is chosen high knowledgeconfidence  lack of knowledgeconfidence  neither or both is possible r
61,· Intense  relaxed mode says about the potential emotional load high  low   neutral  emotional loads are possibler
62,In order to define a robust framework to identify CA arcs in PT we are interested in distinguishing which are the most common communicative actions used in complaint scenarios and how they can be clustered in terms of the attitudes commonly associated with them Table shows the attribute of CA well suited for generalization For example agree^accept  <    >r
63,Table  Extended attributes of communicative actionsr
64,Having built the similarity model for communicative actions we can now compute wordword similarity for them via attributes r
65,To measure the similarity of abstract entities expressed by logic formulas a leastgeneral generalization Plotkin  was proposed for a number of machine learning approaches including explanationbased learning and inductive logic programming Given two logical terms it produces a more general term that covers both r
66,Definition  Let Eand Ebe two terms Term E is a generalization of Eand Eif there exist two substitutions uf073and uf073such that uf073E  Eand uf073E  E The most specific generalization of Eand Eis called the antiunifier Here we apply this abstraction to antiunify such data as texts that are traditionally referred to as unstructured r
67,In this study to measure the similarity between portions of text such as paragraphs sentences and phrases we extend the notion of generalization from logic formulas to the sets of syntactic parse trees of these portions of text If it were possible to define the similarities between natural language expressions at a purely semantic level the leastgeneral generalization would be sufficient However in horizontal search domains where the construction of full ontologies for a complete translation from natural language to logic language is not plausible an extension of the abstract operation of generalization to the syntactic level is required Rather than extracting common keywords the generalization operation produces a syntactic expression that can be semantically interpreted as a common meaning shared by two sentencesr
68,Let us represent a meaning of two NL expressions using logic formulas and then construct the unification and antiunification of these formulas How can we express a commonality between the expressionsr
69,To express the meanings we use the predicates cameraname_of_feature type_of_users in real life we would have a much higher number of arguments and zoomtype_of_zoom The above NL expressions will be represented as followsr
70,where the variables uninstantiated values that are not specified in NL expressions are capitalized Given the above pair of formulas unification computes their most general specializationxa0camerazoomdigital beginner and antiunification computes their most specific generalization camerazoomAnyZoom AnyUserr
71,At the syntactic level we have the generalization of two noun phrases as followsr
72,We eliminate the expressions in square brackets because they occur in one expression and do not occur in another Thus we obtainr
73,NNcamera PRPwith NNzoom which is a syntactic analog to the semantic generalization abover
74,The purpose of an abstract generalization is to find the commonality between portions of text at various levels The generalization operation occurs on the following levelsr
75,At each level except the lowest one the result of the generalization of two expressions is a set of expressions In such a set expressions for which lessgeneral expressions exist are eliminated The generalization of two sets of expressions is a set of the sets that are the results of the pairwise generalization of these expressionsr
76,The result of generalization of two words w^ w <  lemmaw ^ lemmaw  posw ^ posw> r
77,lemmaw ^ lemmaw is either  ww if the words are the same or ‘’ otherwise a placeholder for an arbitrary word if words wand ware differentr
78,posw ^ posw is either partofspeech posw ^ posw or ‘’ otherwise if their partsofspeech are differentr
79,· Only phrase of the same type can be generalized;r
80,· For noun phrases only those with the same head noun can be generalized The generalization result includes this head noun The head of a phrase is the word that determines the syntactic type of that phrase or analogously the stem that determines the semantic category of a compound of which it is a part The rest of the words in phrases is generalized according to Definition r
81,For other types of phrases generalization occurs analogously Notice that English is primarily a headinitial language Structure is descending as speech and processing move from left to right Most dependencies have the head preceding its dependents although there are also headfinal dependencies in parse trees For instance the determinernoun and adjectivenoun dependencies are headfinal as well as the subjectverb dependencies Most other dependencies in English are however headinitial; the mixed nature of headinitial and headfinal structures is common across languages Lehmann r
82,S^S ᴗp  ᴗi p^p  where p and p  are phrases from sentences S and SSof type p NP VP …r
83,We outline the algorithm for generalization two sentences below which concerns paths of syntactic trees rather than subtrees because these paths are tightly connected with language phrases Regarding the operations on trees we follow the work of Kapoor & Ramesh    r
84,Although it is a formal operation on abstract trees the generalization operation yields semantic information about the commonalities between sentences Rather than extracting common keywords the generalization operation produces a syntactic expression that can be semantically interpreted as a common meaning shared by two sentencesr
85,Output A list of lists of generalized phrases for each phrase typer
86,Obtain the parsing tree for each sentence For each word tree node we have a lemma a part of speech and the form of the word’s information This information is contained in the node label We also have an arc to the other node  r
87,Split sentences into subtrees that are phrases for each type verb noun prepositional and others These subtrees are overlapping The subtrees are coded so that the information about their occurrence in the full tree is retainedr
88,Extend the list of phrases by adding equivalence transformations Section r
89,Generalize each pair of subtrees for both sentences for each phrase typer
90,For each pair of subtrees yield an alignment Gildea  and generalize each node for this alignment Calculate the score for the obtained set of trees generalization results r
91,For each pair of subtrees of phrases select the set of generalizations with the highest score the least generalr
92,Form the sets of generalizations for each phrase type whose elements are the sets of generalizations for that typer
93,Filter the list of generalization results for the list of generalizations for each phrase type exclude more general elements from the lists of generalization for a given pair of phrasesr
94,For a given pair of words only a single generalization exists; if words are the same in the same form the result is a node with this word in this form We refer to the generalization of words occurring in a syntactic tree as a word node If the word forms are different eg one is single and the other is plural only the lemma of the word remains If the words are different and only the parts of speech are the same the resultant node contains only the partofspeech information with no lemma If the parts of speech are different the generalization node is empty r
95,For a pair of phrases the generalization includes all the maximum ordered sets of generalization nodes for the words in the phrases so that the order of words is retained Consider the following exampler
96,The digital camera was a good buy today the first Monday of the monthr
97,The generalization is <JJdigital NNcamera> <NNtoday ADVMonday> where the generalization for the noun phrase is followed by the generalization for the adverbial phrase The verb buy is excluded from both generalizations because it occurs in a different order in the above phrases Buy  digital  camera is not a generalization phrase because buy occurs in a different sequence in the other generalization nodesr
98,We can see that the multiple maximum generalizations occur depending on how the correspondence between words is established; multiple generalizations are possible To obey the condition of the maximum we introduce a score for generalization The scoring weights of generalizations are decreasing roughly in the following order nouns and verbs other parts of speech and nodes with no lemma only a part of speech In its style the generalization operation follows the notion of the ‘leastgeneral generalization’ or antiunification if a node is a formula in a language of logic Therefore we can refer to the syntactic tree generalization as an operation of antiunification of syntactic treesr
99,To optimize the calculation of the generalization score we conducted a computational study to determine the POS weights and deliver the most accurate similarity measure possible between sentences Galitsky et al  Galitsky et al  The problem was formulated as finding the optimal weights for nouns adjectives verbs and their forms such as gerund and past tense so that the resultant search relevance is maximized The search relevance was measured as a deviation in the order of search results from the best result for a given query delivered by Google The current search order was determined based on the score of generalization for the given set of POS weights the other generalization parameters having been fixed As a result of this optimization we obtained WNN   WJJ   WRB   WCD   WVB   and WPRP   excluding common and frequent verbs like get takesetput for which WVBcommon  We also establish that W<POS>  different words but the same POS and W<word>  the same word occurring as different POSs in two sentencesr
100,Definition The generalization score or the similarity between the sentences sentand sent can then be expressed as a sum through the phrases of the weighted sum for  the words wordsentand word sentr
101,∑ NP VP …∑ WPOS word generalizationword sentword sentr
102,The maximal generalization can then be defined as the generalization with the highest score Accordingly we define the generalization for phrases sentences and paragraphs The result of the generalization can be further generalized with other parse trees or generalizations For a set of sentences the totality of the generalizations forms a lattice the order of the generalizations is set by the subsumption relation and the generalization score We enforce the associativity of the generalization of parse trees by means of computation it must be verified and the resultant list must be extended each time a new sentence is added Note that such an associativity is not implied in our definition of generalization  r
103,We have manually created and collected a rule base for generic linguistic phenomena from various resources Unlike a text entailment system in our situation we do not require a complete transformation system as long as we have a sufficiently rich set of examples Syntacticbased rules capture the entailment inferences associated with common syntactic structures including the simplification of the original parse tree reducing it into a canonical form extracting its embedded propositions and inferring propositions from the nonpropositional subtrees of the source tree Table r
104,Camera is very stable and has played an important role in filming their weddingr
105,The flash was disconnected when the children went out to play in the yardr
106,I was forced to close the LCD which was blinded by the sunr
107,Digital zoom a feature provided by the new generation of cameras dramatically decreases the images’ sharpness r
108,My customers use their an auto … autofocus camera for polar expeditions their > anr
109,A cell phone can be easily grasped in the palm of a hand The hand can easily grasp the cell phone in its palmr
110,Sony’s LCD screens work as well as Canon’s in a sunny environment The LCD of Sony… as well as that of Canonr
111,It made me use digital zoom for mountain shots I used digital zoom…r
112,Table  Rules of graph reduction for generic linguistic structures The resultant reductions are italicized r
113,The valid matching of sentence parts embedded as verb complements depends on the verbs’ properties and the polarity of the context in which the verb appears positive negative or unknown We used the list of verbs for communicative actions in Galitsky and Kuznetsov  which indicate positive polarity context This list is complemented with a few reporting verbs such as say and announce because opinions are often provided in reported speech in the news domain while authors are usually considered reliable We also used annotation rules to mark the negation and modality of predicates mainly verbs based on their descendent modifiers r
114,An important class of transformation rules involves noun phrases The adjectives of a single noun group can be resorted as well as all nouns except the head one A noun phrase that is a postmodifier of the head noun of a given phrase can be merged with the latter The resultant meaning may be distorted; otherwise we would miss important commonalities between expressions containing noun phrases For an expression ‘NP<of or for> NP we form a single NP with the head noun headNP  headNP playing the role of modifier and an arbitrary sorting of adjectives For example we convert ‘camera with digital zoom’ into ‘digital zoom camera’ headNP  camera r
115,Finding similarity between two paragraphs of textr
116,To rank search results one needs to have a measure of similarity between questions and answers Once a candidate set of answers is obtained by a keyword search using for example TFIDF model we calculate the similarity between the question and each of its candidate answers and rank the latter set respectively in the order of similarity decreaser
117,We will compare three following approaches to assessing the similarity of text paragraphsr
118,· Baseline bagofwords approach which computes the set of common keywordsngrams and their frequencies r
119,· Pairwise sentence matching we will apply syntactic generalization to each pair of sentences and sum up the resultant commonalities This technique has been developed in our previous work Galitsky et al  Section r
120,The first approach is most typical for industrial NLP applications today and the second one has been explored in our previous studies Kernelbased approach to parse tree similarities Moschitti  Zhang et al  as well as tree sequence kernel Sun et al  being tuned to parse trees of individual sentences also belong to the second approach We demonstrate its richness of the third approach here and in the consecutive sections we will provide a stepbystep illustration for how PTs are constructed and generalized We will introduce a pair of short texts articles and compare the above three approaches This example will go through the whole sectionr
121,The first paragraph can be viewed as a search query and the second paragraph can be viewed as a candidate answer A relevant answer should be a closely related text on one hand and not a piece of duplicate information on the other handr
122,Operator ‘’ in the following example and through all the paper denotes generalization operation Describing parse trees we use standard notation for constituency trees … represents subphrase NN JJ NP etc denote partsofspeech and types of subphrases ‘’ will be is a placeholder for a word part of speech or an arbitrary graph noder
123,Iran refuses to accept the UN proposal to end the dispute over work on nuclear weaponsr
124,UN nuclear watchdog passes a resolution condemning Iran for developing a second uranium enrichment site in secretr
125,A recent IAEA report presented diagrams that suggested Iran was secretly working on nuclear weaponsr
126,Iran envoy says its nuclear development is for peaceful purpose and the material evidence against it has been fabricated by the USr
127,UN passes a resolution condemning the work of Iran on nuclear weapons in spite of Iran claims that its nuclear research is for peaceful purposer
128,Envoy of Iran to IAEA proceeds with the dispute over its nuclear program and develops an enrichment site in secretr
129,Iran confirms that the evidence of its nuclear weapons program is fabricated by the US and proceeds with the second uranium enrichment siter
130,The list of common keywords gives a hint that both documents are on nuclear program of Iran however it is hard to get more specific detailsr
131,Iran UN proposal dispute nuclear weapons passes resolution developing enrichment site secret condemning second uranium r
132,Pairwise generalization gives a more accurate account on what is common between these texts  r
133,NNwork IN INon JJnuclear NNSweapons    DTthe NNdispute INover JJnuclear NNS   VBZpasses DTa NNresolution   r
134,VBGdeveloping DT NNenrichment NNsite INin NNsecret  r
135,DTthe NNevidence IN PRPit    VBN VBNfabricated INby DTthe NNPus r
136,Parse Thicket generalization gives the detailed similarity picture which looks more complete than the pairwise sentence generalization result abover
137,NNIran VBGdeveloping DT NNenrichment NNsite INin NNsecret r
138,NNgeneralization<UNnuclear watchdog>  VBpass NNresolution VBG condemning NN Iranr
139,NNgeneralization<Iranenvoy of Iran> Communicative_action  DTthe NNdispute INover JJnuclear NNSr
140,Communicative_action  NNwork  INof NNIran INon JJnuclear NNSweaponsr
141,NNgeneralization <Iranenvoy to UN>  Communicative_action  NNIran NNnuclear NN VBZis INfor JJpeaceful NNpurpose    r
142,Communicative_action  NNgeneralize <workdevelop>  INof NNIran INon JJnuclear NNSweaponsr
143,NNgeneralization <Iranenvoy to UN>  Communicative_action  NNevidence INagainst NN Iran NNnuclear   VBNfabricated INby DTthe NNPus r
144,condemn^proceed enrichment site <leads to>  suggest^condemn  work Iran nuclear weapon r
145,One can feel that PTbased generalization closely approaches human performance in terms of finding similarities between texts To obtain these results we need to be capable of maintaining coreferences apply the relationships between entities to our analysis subject vs relationtothis subject including relationships between verbs develop is a partial case of work We also need to be able to identify communicative actions and generalize them together with their subjects according to the specific patterns of Speech Act Theory Moreover we need to maintain Rhetoric Structure relationship between sentences to generalize at the level of textual discourser
146,Fig and Fig show the dependencybased parse trees for the above texts Tand T Each tree node has labels as partofspeech and its form such as SG for ‘single’; also tree edges are labeled with the syntactic connection type such as ‘composite’ We are not concerned with a particular type of a parse tree representation dependency or constituency as long as we have labels for nodes and vertexesr
147,We now proceed to an example of search query and two answers where coreference establishes a link between two sentences and makes the linked words relevant to a query We will consider two cases for text indexing where establishing proper coreferences inside and between sentences connects entities in an index for proper match with a questionr
148,Question Which specialist doctor should treat my tuberculosisr
149,Text for indexingcandidate answer  … Tuberculosis is usually a lung disease It is cured by doctors specializing in pulmonology r
150,Text for indexingcandidate answer  … Tuberculosis is a lung disease… Pulmonology specialist Jones was awarded a prize for curing a special form of disease r
151,In the first case establishing the coreference link Tuberculosis → disease → is cured by doctors pulmonologists helps to match these entities with the ones from the question In the second case this portion of text does not serve as a relevant answer to the question although it includes keywords from this question Hence at indexing time keywords should be chained not just by their occurrence in individual sentences but additionally on the basis of coreferences One can observer that building PT for an answer online and matching it with question delivers answers which would be determined as irrelevant without building coreference chains This way coreferences and same entity relations as parts of PTs improve search recall From now on we will refer to such chains as phrases from distinct sentences as thicket phrases r
152,We introduce a domain where a pairwise comparison of sentences is insufficient to properly learn certain semantic features of texts This is due to the variability of ways information can be communicated in multiple sentences and variations in possible discourse structures of text which needs to be takes into accountr
153,We consider an example of text classification problem where short portions of text belong to two classesr
154,· Tax liability of a landlord renting office to a businessr
155,· Tax liability of a business owner renting an officer
156,I rent an office space This office is for my business I can deduct office rental expense from my business profit to calculate net incomer
157,To run my business I have to rent an office The net business profit is calculated as follows Rental expense needs to be subtracted from revenuer
158,To store goods for my retail business I rent some space When I calculate the net income I take revenue and subtract business expenses such as office rentr
159,I rent out a first floor unit of my house to a travel business I need to add the rental income to my profit However when I repair my house I can deduct the repair expense from my rental incomer
160,I receive rental income from my office I have to claim it as a profit in my tax forms I need to add my rental income to my profits but subtract rental expenses such as repair from itr
161,I advertised my property as a business rental Advertisement and repair expenses can be subtracted from the rental income Remaining  rental income needs to be added to my profit needs to be reported as taxable profit r
162,Firstly note that keywordbased analysis does not help to separate the first three paragraph and the second three paragraphs They all share the same keywords rentalofficeincomeprofitaddsubtract Phrasebased analysis does not help since both sets of paragraphs share similar phrasesr
163,Secondly pairwise sentence comparison does not solve the problem either r
164,Anaphora resolution is helpful but insufficient All these sentences include ‘I’ and its mention but other links between words or phrases in different sentences needs to be used r
165,Rhetoric structures need to come into play to provide additional links between sentences The structure to distinguish between r
166,renting for yourself and deducting from total income and r
167,renting to someone and adding to income embraces multiple sentences The second clause about addingsubtracting incomes is linked by means of  the rhetoric relation of elaboration with the first clause for landlordtenant This rhetoric relation may link discourse units within a sentence between consecutive sentences and even between first and third sentence in a paragraph Other rhetoric relations can play similar role for forming essential links for text classificationr
168,Once we have a sequence of parse trees for a question and that of an answer how can we match these sequences A number of studies compute pairwise similarity between parse trees Collins and Duffy  Punyakanok et al  Moschitti  However to rely upon discourse structure of paragraphs and to avoid dependence on how content is distributed through sentences we represent the whole paragraphs of questions and answers as a single graph To determine how good is an answer for a question we match their respective PTs and assign a score to the size of common subPTr
169,We extend the syntactic relations between the nodes of the syntactic dependency parse trees towards more general text discourse relations Once we have such relations as “the same entity “subentity “superentity and anaphora we can extend the notion of phrase to be matched between texts In case of single sentences we match noun verb and other types of phrases in questions and answers In case of multiple sentences in each we extend the notion of phrases so that they are independent of how information being communicated is split into sentences Relations between the nodes of parse trees which are other than syntactic can merge phrases from different sentences or from a single sentence which are not syntactically connected We will refer to such extended phrases as thicket phrasesr
170,If words X and Y are connected by a coreference relation an index needs to include the chain of words X XX YY Y where chains X XX and YY Y are already indexed phrases including X and Y Hence establishing coreferences is important to extend index in a way to improve search recall Usually keywords from different sentences can only be matched with query keywords with a low score high score is delivered by intersentence matchr
171,Definition  Thicket phrases for a pair of parse treesr
172,If we have two parse trees  and  of text  and an arc for a relation rP→ P  between the nodes P and P we can now match of  against a phrase of a single sentence or a merged phrases of multiple sentences from r
173,An example of building a thicket phrase by linking two trees is shown in Fig  A thicket phrase can be thought as beginning from a phrase in one sentence then jumping to the tree for another sentence and continuing the phraser
174,Although the generalization is defined as the set of maximal common subgraphs its computation is based on matching phrases To generalize a pair of sentences we perform chunking and extract all noun verb prepositional and other types of phrases from each sentence Then we perform generalization for each type of phrases attempting to find a maximal common subphrase for each pair of phrases of the same type The resultant phraselevel generalization can then be interpreted as a set of paths in resultant common subtrees Galitsky et al r
175,Generalization of parse thickets being a maximal common subparse thicket can be computed at the level of phrases as well as a structure containing maximal common subphrases However the notion of phrases is extended now thicket phrases can contain regular phrases from different sentences The way these phrases are extracted and formed depends on the source of nonsyntactic link between words in different sentences thicket phrases are formed in a different way for communicative actions and RST relations Notice that the set of regular phrases for a parse thicket is a subset of the set of thicket phrases all phrases extracted for generalization Because of this richer set of phrases for generalization the parse thicket generalization is richer than the pairwise thicket generalization and can better tackle variety in phrasings and writing styles as well as distribution of information through sentencesr
176,We will now outline the algorithm of forming thicket phrases Most categories of thicket arcs will be illustrated below r
177,Fig  An arc which connects two parse trees for two sentences in a text on the top and the derived set of extended trees on the bottom r
178,Form a list of previous sentences in a paragraph Sprevr
179,If this word is a pronoun find all nouns or noun phrases in the Sprev which arer
180,If this word is a noun find all nouns or noun phrases in the Sprev which are r
181,Form the phrase for its subject VBCAphrase including its verb phrase Vphr
182,Find a preceding communicative action VBCAphrasefrom Sprev with its subject r
183,and form a thicket phrase VBCAphrase VBCAphraser
184,Form the phrase for the pair of phrases which are the subjects VBRSTphrase r
185,VBRSTphrase of this RST relation VBRSTphrasebelongs to Sprevr
186,Figs and show examples of Parse Thickets for the above paragraphs In addition to syntactic links between words in a sentence words in a paragraph are connected with links of the different nature To form a complete formal representation of a paragraph we attempt to express as many links as possible The most obvious links are the same entities which is a partial case of coreferences A less trivial tasks is to identify a subentity relation; an external resource needs to be consulted In Fig we have a subentity link IAEA → UN The fact that the former is a subentity in this case suborganization is either obtained by using lookups available as a part of generalpurpose NLP system like OpenNLP Stanford NLP Lee at al  GATE LingPipe and others or using web mining of sites like Wikipedia Freebase and others In more complex cases such as multiwords more complex web mining settings are required such as Velásquez et al  Galitsky et al r
187,The communicative links reflect the discourse structure associated with participation or mentioning of more than single agent in text The links form a sequence connecting the words for communicative actions either verbs or multiwords implicitly indicating a communicative intent of a person We have thoroughly investigated the structure of how communicative actions occur in text in our study of argumentation in customer complaints which is one of the most complicated cases of communicative actionsbased discourse Galitsky et al  r
188,The main observation concerning communicative actions in relation to finding text similarity is that their subjects need to be generalized in the context of these actions and that they should not be generalized with other “physical actions Hence we generalize the individual occurrences of communicative actions together with their subjects as well as their pairs as discourse “steps Generalization of communicative actions can also be thought from the standpoint if matching the verb frames such as VerbNet Palmer  For a communicative action we distinguish an actor one or more agents being acted upon and the phrase describing the features of this action In the next section we will illustrate how respective arguments of verbs are generalizedr
189,Notice the three categories of the formed thicket phrasesr
190,Once we collected the thicket phrases for texts Tand T we can do the generalization When we generalize thicket phrases from various categories the following constraints should be taken into account Table  r
191,Table  Which phrase types can be generalized with each otherr
192,For example entitybased thicket phrase can be generalized with regular phrases but with neither RST nor SpActTr
193,Fig  Three instances of common subPTs are shown as connected cloudsr
194,In Section we defined and showed how to construct PTs We also introduced generalization of individual parse trees Based on that in this section we introduce generalization of PTs which is based on generalization of individual parse trees on one hand and on generalization of discourse structures on the other hand For coreferences and entityentity type of relation we link them and consider the nodes in PT identical  For RST we attempt to extract an RST relation and form a thicket phrase around it including a placeholder for RST relation itself Galitsky et al  For SpActT we use a vocabulary of communicative actions to find their subjects Galitsky & Kuznetsov  add respective arcs to PT and form the respective sequence of thicket phrasesr
195,Two connected clouds on the right of Figshow the generalization instance based on RST relation “RCTevidence This relation occurs between the phrases r
196,evidenceforwhat  Iran’s nuclear weapon program and whathappenswithevidence Fabricated by USA on the rightbottom and r
197,evidenceforwhat against Iran’s nuclear development and whathappenswithevidence Fabricated by the USA on the righttopr
198,Notice that in the latter case we need to merge perform anaphora substitution the phrase ‘ its nuclear development’  with ‘evidence against it’ to obtain ‘evidence against its nuclear development’  Notice the arc it  development according to which this anaphora substitution occurred Evidence is removed from the phrase because it is the indicator of RST relation and we form the subject of this relation to match Furthermore we need another anaphora substitution  its Iran to obtain the final phraser
199,As a result of generalizations of two RST relations of the same sort evidence we obtainr
200,Iran nuclear NNP  – RSTevidence – fabricate by USAr
201,Notice that we could not obtain this similarity expression by using sentencelevel generalizationr
202,Green clouds at indicate the subPTs of  Tand Twhich are matched We show three instances of PT generalizationr
203,Definition  RSTtypephrase ^ RST typephrase   RST typeᴗ phrase^ phraser
204,when typetype otherwise  Notice that the relation itself is retained to be further generalized if requiredr
205,Communicative actions are used by text authors to indicate a structure of a dialogue or a conflict Searle  Hence analyzing the communicative actions’ arcs of PT one can find implicit similarities between texts We can generalizer
206,one communicative actions from with its subject from Tagainst another communicative action with its subject from Tcommunicative action arc is not used ;r
207,a pair of communicative actions with their subjects from Tagainst another pair of communicative actions from Tcommunicative action arcs are used r
208,In our example we have the same communicative actions with subjects with low similarityr
209,condemn  ‘Iran for developing second enrichment site in secret’ vs condemn ‘the work of Iran on nuclear weapon’  or different communicative actions with similar subjects r
210,Looking on the left bottom of Fig one can observe two connected clouds the two distinct communicative actions dispute and condemn have rather similar subjects ‘work on nuclear weapon’ Generalizing two communicative actions with their subjects follows the rule generalize communicative actions themselves and ‘attach’ the result to generalization of their subjects as regular subtree generalization Two communicative actions can always be generalized which is not the case for their subjects if their generalization result is empty the generalization result of communicative actions with these subjects is empty too The generalization result here for the case above isr
211,Generalizing two different communicative actions Fig  is based on their attributes and is presented elsewhere Galitsky et al r
212,condemn  second uranium enrichment site    ↔    proceed develop an enrichment site in secret r
213,suggest Iran is secretly working on nuclear weapon ↔ condemn the work of Iran on nuclear weaponr
214,condemn  second uranium enrichment site    ↔  condemn the work of Iran on nuclear weaponr
215,suggest Iran is secretly working on nuclear weapon ↔  proceed develop an enrichment site in secret r
216,gives zero result because the arguments of condemn from Tand Tare not very similar Hence we generalize the subjects of communicative actions first before we generalize communicative actions themselvesr
217,Fig A fragment of PT showing the mapping for the pairs of communicative actionsr
218,We conclude the section by definition of generalization for a pair of CAs and also for a pair of pairs of CAsr
219,Definition  CAtypephrase ^ CAtypephrase   CAtype CAtypephrase^ phrase r
220,We have shown how to compute similarity between PTs via phrases That was an approximation of finding similarity between two graphs considering their selected paths which correspond to phrases Now we focus on information lossfree approach where we compute similarity between two graphs in a classical linguistic domainindependent way Similarity between graphs is measured by the size of the maximal common subgraph Koch r
221,To find maximal subPT we use a reduction of the maximal common subgraph problem to the  maximal clique problem Moon and  Moser  Bron and Kerbosch  by constructing the edge product The main difference with the traditional edge product is that instead of requiring the same label for two edges to be combined we require nonempty generalization results for these edges Though computationally not optimal this approach is convenient for prototyping Although for the trees this problem is On for the general case of graphs finding maximum common subgraphs is NP hard Kann  r
222,We construct an edge product PT Let  and  be PTs with nodes V and edges E where  is a function assigning labels to the vertices and L is a finite nonempty set of labels for the edges and vertices The edge product PT  includes the vertex set  in which all edge pairs with and  have to produce nonempty generalization in their edge labels Also these edge pairs must produce nonempty generalizations in their corresponding end vertex labels Let  and  The labels coincide if  and  and r
223,There is an edge between vertices  where  and  if two edge pairs are compatible meaning that they are distinct and  Also either condition for these edges of resultant PT should holdr
224,in  are connected via a vertex of the label which produces nonempty generalization with the label of the vertex shared by in  We label and call them cedges orr
225,and are not adjacent in  and in  respectively We label and call them dedgesr
226,To get a common subPT in  and  each edge pair in  and  vertex pair in  has to have generalizable label with all other edge pairs in  and  vertex pair in  which are forming a common subgraph In this way a clique in  corresponds to common subPTs  and r
227,A subset of vertices of G is said to be a clique if all its nodes are mutually adjacent A maximal clique is one which is not contained in any larger clique while a maximum clique is a clique having largest cardinality Vismara and Valery  After finding all maximal cliques for all pairs representing question and answer for instance we look through all results and range them due to cliques cardinality In this case the more edge pairs the result of generalization of two paragraphs contains the higher the relevance between two portions of text isr
228,Applying some effective taking into account specific features of thicket graphs approaches to common subgraph problem is a subject of our future work Also we are going to use more complex types of generalization such as pattern structures Ganter and Kuznetsov  instead of pairwise generalization The clique problem is the computational problem of finding a maximum clique or all cliques in a given graph which is NPcomplete one of Karps NPcomplete problems Karp  We build the edge product algorithm for PT case ouselves and integrated it with the available solution for the click problem of JGraphT library r
229,After finding all maximal common subgraph for all pairs representing question and answer for instance we rank results according to the score based on size of common substructure and its linguistic properties Each part of speech has its own score calculated from seacrch engine statisticsr
230,Application of PT generalization for search occurs according to the following scenario For the question and candidate answer we build a pair of PTs Then we perform generalization of PTs either without loss of information finding a maximum common PT subgraph or with the loss of information approximating the paths of resultant subgraph by generalizing thicket phrases Search relevance score is computed accordingly as  a total number of vertexes in a common maximum subgraph in the first case and calculating the number of words in maximal common subphrases taking into account weight for parts of speech Galitsky et al  in the second case This scenario will be evaluated in details in the section to followr
231,The system architecture is depicted in Fig  There are three system components which include Parse Thicket building phraselevel processing and graph processingr
232,The textual input is subject to a conventional text processing flow such as sentence splitting tokenizing stemming partofspeech assignment building of parse trees and coreferences assignment for each sentence This flow is implemented by either OpenNLP or Stanford NLP and the parse thicket is built based on the algorithm presented in this paper The coreferences and RST component strongly relies on Stanford NLP’s rulebased approach to finding correlated mentions based on the multipass sievesr
233,The graphbased approach to generalization relies on finding maximal cliques for an edge product of the graphs for PTs being generalized As it was noticed earlier the main difference with the traditional edge product is that instead of requiring the same label for two edges to be combined we require nonempty generalization results for these edges Hence although the parse trees are relatively simple graphs parse thicket graphs reach the limit of realtimes processing by graph algorithmsr
234,The system architecture serves as a basis of OpenNLP – similarity component which is a separate Apache Software foundation project accepting input from either OpenNLP or Stanford NLP It converts parse thicket into JGraphT httpjgraphtorg objects which can be further processed by an extensive set of graph algorithms In particular finding maximal cliques is based on Bron and Kerbosch  algorithm Code and libraries described here are also available at httpsvnapacheorgreposasfopennlpsandboxopennlpsimilarity The system is ready to be plugged into Lucene library to improve search relevance Also a SOLR request handler is provided so that search engineers can switch to a PTbased multisentence search to quickly verify if relevance is improvedr
235,The second and third components are two different ways to assess similarity between two parse thickets Phraselevel processing for the phrases of individual sentences has been described in detail in our previous studies Galitsky et al  In this study we collect all phrases for all sentences of one paragraph of text augment them with thicket phrases linguistic phrases which are merged based on the intersentence relation and generalize against that of the other paragraph of textr
236,Find communicative actions and set relations between them and their subjectsr
237,Find rhetoric markers and form rhetoric structure relationsr
238,Obtain thickets phrases by merging ones from distinct sentencesr
239,For two sets of thicket phrases select a pair of phrases Align them and find a maximal common subphraser
240,Remove subphrases from the list of resultant phrasesr
241,Form edges of the PT graph by combining parse tree edges and coref SpAct & RST arcsr
242,Form all nodes of parse trees for individual sentences as the nodes of the PT graphr
243,For two graphs build a set of nodes for the edge product graph for all pairs of edges from PT graphs which can be generalizedr
244,Calculate the score for maximal common subgraphs based on cliquesr
245,Fig  Architecture of Parse Thicket processing systemr
246,PTs and their generalizations are important for domainindependent text relevance assessment We propose a number of evaluation scenarios to compare the relevance performance of PTsupported search and its various forms of reduction We demonstrate that simplifying construction of PT discarding one or another linguistic feature we lose relevance We also compare the performance of complete PTsupported search with other stateoftheart question answering systems dealing with multisentence queries and or multisentence questionsr
247,In our earlier studies we explored the following cases for how generalization supports question answeringr
248,· Single sentence question against single sentence answer Galitsky et al r
249,· Single sentence question against multiple sentences in the answer by pairwise generalization and summing up the score Galitsky et al r
250,We will reevaluate these cases in the unified framework to compare the results with the focus of the current paper paragraphsized question against a paragraphsized answer or its snippetr
251,In this section we demonstrate that pairwise sentence generalization approach lacking discourse features can be outperformed by PT approachr
252,Having formed a pair of PTs for question and answer we will comparer
253,· Pairwise sentencesentence generalization ignoring intersentence links versus full PT generalizationr
254,· Phrasebased approximation of  generalization versus finding maximum common subparse thicketsr
255,· Contribution of two sources of discourse structure RST and SpActT for search relevancer
256,· Role of PTsupported search for various domain from product search to socialr
257,In terms of complexity of queries and answers we will proceed from single sentences queriesanswers to multiple sentences queriesanswersr
258,We conducted evaluation of relevance of syntactic generalization – enabled search engine based on Bing search engine APIs Instead of maintaining search index ourselves for the purpose of evaluation we relied on Bing index and baseline search relevance In terms of reproducibility of the experimental results in this study since we measure a relative relevance improvement compared to Bing’s baseline once we have a fixed publically available set of queries it is acceptable From Bing search results we get page titles snippets and also extract paragraphs of text from the original webpager
259,For an individual query the relevance was estimated as a percentage of correct hits among the first thirty using the values correct marginally correct incorrect compare with Resnik and Lin  Accuracy of a single search session is calculated as the percentage of correct search results plus half of the percentage of marginally correct search results Accuracy of a particular search setting query type and search engine type is calculated averaging through search sessionsr
260,For our evaluation we use customers’ queries to eBay entertainment and productrelated domains from simple questions referring to a particular product a particular user need as well as a multisentence forumstyle request to share a recommendation In our evaluation we split the totality of queries into nounphrase class verbphrase class howto class and also independently split in accordance to query length from keywords to multiple sentences The evaluation was conducted by the authors  To compare the relevance values between search settings we used first search results obtained for a query by Bing API and then reranked them according to the score of the given search setting syntactic generalization scorer
261,The list of products which serves the basis of queries is available at httpscodegooglecomprelevancebasedonparsetreesdownloadsdetailnameQueriesetxls We took each product and found a posting somewhere on the web typically a blog or forum posting about this product requesting a particular information or addressing a particular user feature need or concern From such extended expression containing product names we formed the list queries of desired complexityr
262,To estimate the statistical significance of results of relevance improvement we estimate the standard deviation  of  the difference between the baseline average relevance and the one obtained by a particular reranking For the evaluation set of search sessions for both baseline and AFPsupported search we haver
263,To do that we assume that the search accuracy can be described by a normal distribution and the number of searches is large enough Kohavi  r
264,Pairwise sentence generalization for questionanswer similarityr
265,There are a number of limitations in how the modern search engines attempt to find the occurrence of query keywords in a single sentence in a candidate search results If it is not possible or has a low search engine score multiple sentences within one document are used However modern search engines have no means to determine if the found occurrences of query keywords are related to each other related to the same entity Our first evaluation setting the pairwise matching of parse tree for questions and answers addressing this issue and showing that once parse trees are taken into account in addition to keywords relevance is increasing In our previous studies we already demonstrated this fact and in this project we repeat this evaluation setting to conform to the consecutive ones based on PTsr
266,Table shows the search relevance evaluation results for singlesentence answers   The first and second columns show the types of phrasessentences serving as queries The third column shows the baseline Bing search relevancy The fourth and fifth columns shows relevance of reranked search for snippets and original paragraphs from the webpage and the sixth column shows relevance improvement compared with the baseliner
267,One can observe that the higher the query complexity the higher the impact of generalization for question and answer for reranking For the simplest queries there is no improvement For  keywords phrases improvement starts being noticeable of  and reaches  and  for twothree sentence queries respectively As the absolute precision of search naturally drops when queries become more complex relative contribution of syntactic generalization increasesr
268,In most cases using original text is slightly better than using snippets by about  except the case of the simple queries In the case of  keywords the use of generalization is unreasonable so the results can be even distorted and reranking by generalization score is not meaningfulr
269,Table  Evaluation of pairwisesentence generalization searchr
270,Relevancy of baseline Bing search  averaging over searchesr
271,Relevancy of resorting by pairwise sentence generalization with snippets  averaging over searchesr
272,Relevancy of resorting by pairwise sentence generalization with text on original page  averagingr
273,Relevancy  improvement resorted relevance for Bingr
274,We did not find a significant correlation between a query type phrase type and search performance with and without syntactic generalization for these types of phrases Verb phrases in questions did well for multisentence queries perhaps because the role of verbs for such queries is more significant than for simpler queries where verbs can be frequently ignoredr
275,Single sentence query and answer distributed through multiple sentencesr
276,It is hard for modern search engines to determine for a given occurrence of keywords being in different sentences if they are related to each other and are related to the query term Once we establish links between words in different sentences it should help in determining how these words are potentially connected with the query keywords We will evaluate this observation in this sectionr
277,Relevance improvement for the queries ranging from a few keywords to a whole sentence is shown in Table  One can see that the simplest cases of short query and a single compound sentence gives about  improvement PTbased relevance improvement stays within  as query complexity increases by a few keywords and then increases to  as query becomes a whole sentence For the same query complexity naturally search accuracy decreases when more sentences are required for answering this query However contribution of PTs does not vary significantly with the number of sentences the answer occurs in one two  or three  PTsupported search outperforms the pairwise generalizationsupported search for the similar setting of  complex phrase to one sentence query Table rows  by  r
278,We separately measure search relevance when PT is samesubsuperentity  based coreferencesbased  RSTbased and SpActTbased columns  Our hybrid approach includes all these sources for links altogether column  We consider all cases of questions phrase one two and three sentences and all cases of search results occurrences compound sentence two and three sentences and measured how PT improved the search relevance compared to original search results of Bing r
279,We found that contribution of intersentence links decreases in the following order coreferences r
280,samesubsuperentity  RST and SpActT for simpler queries and samesubsuperentity  SpActT r
281,coreferences  RST for the full sentence queries; the deviation between their contribution is within a percent or two What is visible is that all of these sources of discourse information  in a standalone mode improve the relevance hence their hybrid is indeed required for overall PTsupported search This conclusion is made taking into account that these sources are independent relevance improvers since they are based on mechanisms and linguistic theories of totally different naturesr
282,Table  Search improvement results for PT approach single sentence query and multisentence answerr
283,Relevancy of resorting by PT generalization based on coreferences r
284,Relevancy of resorting by PT generalization based on samesubsuperentity  r
285,Relevancy of resorting by PT generalization based on RST  r
286,Relevancy of resorting by  PT generalization based on SpActT  r
287,Relevancy of resorting by hybrid coreferenceentityRSTSpActT forest generalization  r
288,Relevancy improvement for  PT approach comp to baseliner
289,We proceed to evaluation of how generalization of PTs can improve multisentence search where one needs to compare a query as a paragraph of text against a candidate answer as a paragraph of text snippet Evaluation results show the accuracies in percentages averaging over searches r
290,When the query complexity increases from one sentence to four sentences the contribution of PT increases from  for a single sentence to  for double sentence and then to  for triple sentence and stays the same for four sentences in the query Although as queries become more complicated overall drop of PTsupported relevance is not lower than the respective drop of baseline relevance the significance of the relevance improvement is obvious Table r
291,We observe that contribution of intersentence links decreases in the following order SpActT  coreferences samesubsuperentity  and RST and for two sentence queries and SpActT RST coreferences and samesubsuperentity Hence for longer queries and answers the role of discourse theories is higher than that of for simpler queries where coreferences and samesubsuperentity turned out to be more importantr
292,RST for the full sentence queries; the deviation between their contribution is within a percent or twor
293,Table  Relevancy improvement for query and answers as paragraphsr
294,Phrasebased and graphbased implementation of generalizationr
295,Once we know that we should leverage all available discourserelated information for better search relevance we investigate various approaches to generalization computation and also explore performance in various domains where search is associated with multisentence questions and multisentence answers Moreover for each domain and queryanswer complexity once we obtain search results from Bing Search API we either take its snippet or download the original webpage and extract the respective paragraph to form its PTr
296,Three domains are used in evaluation in this section Table  r
297,Product recommendation where a user explicitly or implicitly according to a belief of an automated agent is requesting information about products This agent finds a chat and determines user intent from text analyzing epistemic states of this user and mention that this user is seeking a productrelated recommendation The input for such the recommendation is a few sentences of text Given this input a search request is sent to Bing Blogs and Forums and candidate recommendations are filtered out in terms of relevance by PT generalization The data is collected from eBaycom and StubHubcomr
298,Travel recommendation where an agent reads chats about travel activities things to do and hotels The agent tracks travel chats forums blogs and trip reports and produces recommendation when requested or when user intent is detectedThe data was collected at UpTakecom acquired by Grouponcomr
299,Facebook automated posting agent which issues posts on  behalf of its human host For the purpose of promoting social activity and enchance communications with the friends other than most close ones this agent is authorized to comment on postings images videos and other media Given one or more sentence of user posting or image caption this agent issues a Bing Web and Bing Blogs APIs search request and filters the results for relevance Experiments with Facebook account were conducted using OpenGraph involving a number of personal accounts Fig r
300,Fig  The Facebook agent is posting a message on behalf of its human host This message is obtained from Bing Blogs API and is supposed to be relevance unlike the most of Facebook ads on the rightr
301,The value of PT based generalization varies from domain to domain significantly mostly depending on the writing style and use of terminology by the authors presenting their opinions on the products When things in a domain are named uniquely and the typical writing style is plain enumeration of product features contribution of PT is the least shopping product domains On the contrary where writing styles vary a lot and different people name the same things differently in such horizontal domain as Facebook the baseline relevance is low the resultant relevance is lower  than in the other domains  r
302,One can see that contribution of SpAct source varies from domain to domain In product and travel recommendations its contribution is low about  At the same time in the Facebook domain where the description of interaction between people do occur its contribution reaches r
303,Proceeding from Snippets to original paragraphs in a webpage gives further  increase for both thicket phrasebased and graphbased computation of PTr
304,Graphbased algorithms Bunke et al  Conte et al  for PT generalization are associated with much higher complexity than phrase based At the same time loss of information for a phrase base approach leads to less than  drop in the resultant relevance Hence we select the phrasebased approach to PT generalization as most efficientr
305,Table  Evaluation results for various search domains and for various implementations of PT generalizationr
306,Relevance of baseline Bing search  averaging over searchesr
307,Relevance of  PTphrase  generalization search  averaging over searches using original text without SpAtcTr
308,Relevance of  PTphrase generalization search  averaging over searches using snippetsr
309,Relevance of  PTphrase generalization search  averaging over searches using original textr
310,Relevance of  PT graph generalization search  averaging over searches using snippetsr
311,Relevance of  PT graph generalization search  averaging over searches using original textr
312,Comparison of search performance with other studiesr
313,In this section we evaluate the search task which is not specific to the given study but constitutes a standard testbed for question answering systems We obtained a list of entitybased queries some of which require an answer contained in multiple sentences The evaluation set of questions was obtained from r
314,We took queries from this list and converted into short phrases longer phrases and extended by  sentences to match the above evaluation cases There are also search sessions per query answer typesr
315,These search evaluation settings for Table were inspired by TREC  whose goal was to perform entityoriented search tasks on the web Many user information needs concern entities people organizations locations products etc which are better answered by returning specific objects instead of just any type of documents  Like Trec Entity track we used normalized Discounted Cumulative Gain NDCG the normalized discounted cumulative gain at rank R the number of primary and relevant search results for that topic where primary pages get gain and relevant pages get gain  This is unlike our previous evaluation settingsr
316,The intuition behind the Discounted Cumulative Gain approach is that highly relevant documents appearing lower in a search result list should be penalized as the graded relevance value is reduced logarithmically proportional to the position of the result The discounted CG accumulated at a particular rank positionxa0xa0is defined asr
317,Where relis the relevance of the first result and  reli  is the relevance of the consecutive  results i< Dividing the obtained DCG by the DCG of the ideal ranking we obtain a normalized DCGr
318,TREC evaluation was conducted in a similar environment relying on Bing Yahoo and other web knowledge sourcesr
319,In the example search result Fig  PTsupported search reranks the snippets to find the entity occurring in an expression ENTITY is  <query with substituted WHword> In most cases ENTITY occurs in a different sentence to the one which is best matched with <query with substituted WHword>r
320,Fig  Bing search results for the entitybased query with expected answer “Michelangelo’s Pieta“ obtained by APFsupported searchr
321,Relevancy of baseline Yahoo search NDCGR averaging over searchesr
322,Relevancy of baseline Bing search NDCGR averaging over searchesr
323,Relevancy of resorting by pairwise sentence generalization NDCGR averaging over searchesr
324,Relevancy of resorting by hybrid RSTSpActT forest generalization NDCGR averaging over searchesr
325,Relevancy improvement for  parse forest approach comp to pairwise generalizationr
326,We compare the results of PTbased search with that of the TREC Entity Track participants Table  The best teams BIT Jiang et al  and FDWIM had slightly higher relevance NDCG  and  respectively and the rest of the teams including Purdue NiCT  ICTNET and  UWaterlooEng obtained a lower relevance compared to APFbased approach Balog et al  In the current study for the hybrid RSTSpActT forest generalization approach we obtained NDCG     for sentence answers sentence answers and sentence answers respectively It worth mentioning that the above approaches are oriented at answering entitybased questions whereas the current approach targets the cases where found keywords are distributed through multiple sentenced in the search result snippet This evaluation covers the overlap of these two cases and we believe PT performance is satisfactory herer
327,For the entity based search from the TREC Entity Track queries the improvement of search by using PT and especially RST is higher than for the search in Section  for both short and long queries This is due to the fact that entitybased questions take advantage of the coreferences and RST relations such as elaboration which are typical in the paragraphs of text answering entitybased questions Since both short and long entitybased phrases heavily rely on the coreferences and RST there is a relatively uniform improvement of search accuracy compared to the search in previous evaluation subsections where PT contribution for more complicated questions is higherr
328,Over the past few years complex questions have been the focus of much attention in the automatic questionanswering community Most current complex QA evaluations included the AQUAINT Relationship QA Pilot the TREC Relationship QA Task and the TREC entity task Jiang et al  whose results we compared to ours and Document Understanding Conference DUC These evaluations require systems to return unstructured lists of candidate paragraphlength answers in response to a complex question that are responsive relevant and coherent For the DUC settings Chali et al  reports  improvement from  to  of parse tree similarity based approach over keywordbased lexical for the Kmeans framework Cahel et al  which roughly corresponds to our improvement of single sentence generalizationbased search over the baseline Section  r
329,Moschitti and Quarteroni  report the accuracy Fmeasure on the TRECQA dataset of  ±  for a bagofwords classifier and  ±  for the optimal combination of tree kernels If one reranks deteriorates search engine search results by keyword occurrence only and then compare with the APF performance a similar performance would be observed Singlesentence generalization relies on similar linguistic information about questions and answering as tree kernel and APF extension becomes noticeable compared to commercial search engine results rather than bagofwords systemsr
330,General pattern structures consist of objects with descriptions called patterns that allow a semilattice operation on them Ganter & Kuznetsov  In our case for paragraphs of text to serve such objects they need to be represented by structures like parse thickets which capture both syntactic level and discourselevel information about texts Pattern structures arise naturally from ordered data eg from labeled graphs ordered by graph morphisms  In our case labeled graphs are parse thickets and morphisms are the mappings between their maximal common subgraphs Besides finding maximal common subgraph PTs can be viewed from the standpoint of graph search problem For example Mandow   describes a new general algorithm for graph search problems with additive lexicographic goals The use of lexicographic goals in the formulation of search problems provides greater control and expressive power over the properties of solution paths in the algorithm called METALANr
331,One of the first systems for the generation of conceptual graph representation of text is described in Sowa and Way  It uses a lexicon of canonical graphs that represent valid possible relations between concepts These canonical graphs are then combined to build a conceptual graph representation of a sentence Since then syntactic processing has dramatically improved delivering reliable and efficient results  PTs can be viewed as conceptual graphs which are derived automatically from Concept mining has found a number of applications as well Bichindaritz & Akkineni r
332,Hensman & Dunnion  describes a system for constructing conceptual graph representation of text by using a combination of existing linguistic resources VerbNet and WordNet However for practical applications these resources are rather limited whereas syntactic level information such as syntactic parse trees is readily available Moreover building conceptual structure from individual sentences is not as reliable as building these structures from generalizations of two and more sentences r
333,In this study we attempt to approach conceptual graph level Sowa  Polovina & Heaton  using pure syntactic information such as syntactic parse trees and applying learning to it to increase reliability and consistency of resultant semantic representation The purpose of such automated procedure is to tackle information extraction and knowledge integration problems usually requiring deep natural language understanding Galitsky  and cannot be solved at syntactic levelr
334,Whereas machine learning of syntactic parse trees for individual sentences is an established area of research the contribution of this paper is a structural approach to learning of syntactic information at the level of paragraphs A number of studies applied machine learning to syntactic parse trees Collins & Duffy  convolution kernels being the most popular approach Haussler  Parse tree kernels are also used for plagiarism detection r
335,Harabagiu et al  introduce a new paradigm for processing complex questions that relies on a combination of question decompositions based on a Markov chain factoid QA techniques and multidocument summarization The Markov chain is implemented by following a random walk with a mixture model on a bipartite graph of relations established between concepts related to the topic of a complex question and subquestions derived from topicrelevant passages that manifest these relations Decomposed questions are then submitted to a stateoftheart QA system in order to retrieve a set of passages that can later be merged into a comprehensive answer The authors show that question decompositions using this method can significantly enhance the relevance and comprehensiveness of summarylength answers to complex questions This approach does not rely on the association between concepts available for decomposed simpler questions from the commercial search engines In the current study we achieve relevance based on better match of questions to answers obtained by search engines which have learned the best matches for decomposed questions relying on user selections Hence in our evaluation settings we skip decomposition and do not do summarization achieving higher relevance by finding relevant documents among the candidate set which has been formed by search engine APIs Moreover to the best of our knowledge no approach to answering complex questions is relying on linguistic discourse theoriesr
336,The evaluations in Harabagiu et al  have shown that the question decompositions lead to more relevant and complete answers Moreover the coverage of auto generated question decompositions when compared with the questions generated from the answer summary are better indicators of answer quality than the relevance score to the complex question The question coverage for automatic methods is  of the coverage of questions produced by humans Within the framework of the current study question decomposition occurs via matching with various parse trees in the answers If the baseline answers are reranked by humans the coverage recall is about  higher than the automated system in the lower section of Table where sentence questions are matched with sentence answers recall values are not shown in the tabler
337,Use of PT allows for domainindependent search applications desired more than three decades ago Xing & Li  proposes a domainindependent approach to constructing natural language interfaces for applications Domain independence provides generality to natural language interfaces A hierarchical structure for natural language processing and a representation language the Intermediate Carrier Language are introduced A special phase of natural language processing called domain compiling is also proposed and describedr
338,Learning of PTs can be viewed as learning cases in the framework of casebased reasoning Richter compares casebased reasoning with other methods searching for knowledge considering it as a resource that can be traded It has no value in itself; the value is measured by the usefulness of applying it in some process Such a process has infoneeds that have to be satisfied The concept to measure this is the economical term utility In general utility depends on the user and its context ie it is subjective The author introduces the levels of contexts from general to individual and illustrates that CaseBased Reasoning on the lower ie more personal levels is quite useful in particular in comparison with traditional informational retrieval methodsr
339,Yang and Soo  develop a technique to extract conceptual graphs from a patent claim using syntactic information such as POS and dependency tree as well as semantic information such as the background ontology Vicient et al  Due to extensive technical domain terms and long sentences in patent claims it is difficult to apply a NLP Parser directly to parse the plain texts in the patent claim This paper combines techniques such as finite state machines PartOfSpeech tags conceptual graphs domain ontology and dependency tree to convert a patent claim into a formally defined conceptual graph The method of a finite state machine splits a lengthy patent claim sentence into a set of shortened subsentences so that the NLP Parser can parse them one by one effectively The PartOfSpeech and dependency tree of a patent claim are used to build the conceptual graph based on the preestablished domain ontology The result shows that  subsentences split from patent claims can be efficiently parsed by the NLP Parserxa0r
340,Whereas machine learning of syntactic parse trees for individual sentences is an established area of research Haussler ; Collins and Duffy    Moschitti  the contribution of this paper is a structural approach to learning of syntactic information at the level of paragraphs  Galitsky   observed how employing a richer set of linguistic information such as syntactic relations between words assists relevance tasks To take advantage of semantic discourse information we introduced parse thicket representation and proposed the way to compute similarity between texts based on generalization of parse thickets In this work we build the framework for generalizing PTs as sets of phrases to rerank search results obtained via keyword searchr
341,The operation of generalization to learn from parse trees for a pair of sentences turned out to be important for search reranking Once we extended it to learning parse thickets for two paragraphs we observed that the relevance is further increased compared to the baseline Bing search engine API which relies on keyword statistics in the case of multisentence query Parse thicket is intended to represent the syntactic structure of text as well as a number of semantic relations for the purpose of the real time reranking of the search results Parse thickets include relations between words in different sentences such that these relations are essential to perform a broad match of queries and answers r
342,We considered the following sources of relations between words in sentences coreferences taxonomic relations such as subentity partial case predicate for subject etc rhetoric structure relation and speech acts We demonstrated that search relevance can be improved if search results are subject to confirmation by parse thicket generalization where answers occur in multiple sentences We showed that each source contributes on its own to improve relevance and altogether intersentence links are fairly important for finding relevant complex answers to complex questionsr
343,Traditionally machine learning of linguistic structures is limited to keyword forms and frequencies At the same time most theories of discourse are not computational they model a particular set of relations between consecutive states In this work we attempted to achieve the best in both worlds learn complete parse tree information augmented with an adjustment of discourse theory allowing computational treatmentr
344,To the best of our knowledge this is one of the first works in learning a semantic discourse to solve a search relevance problem using on a sequence of parse trees Instead of using linguistic information of individual sentences we can now compute text similarity at the level of paragraphs r
345,We have contributed the PTbased functionality to OpenNLP so that search engineers can easily plug it in their search infrastructure The algorithms for PT construction PT generalization via phrases and via graphs are available at httpscodegooglecomprelevancebasedonparsetreesr
346,One approach to learning parse trees is based on tree kernels where the authors propose a technique oriented specifically to parse trees and reduce the space of all possible subtrees Partial tree kernel Moschitti  allows partial rule matching by ignoring some child nodes in the original production rule Tree Sequence Kernel or TSK Sun et al  adopts the structure of a sequence of subtrees other than the single tree structure strictly complying with the original production rules Leveraging sequence kernel and tree kernel TSK enriches sequence kernel with syntactic structure information and enriches tree kernel with disconnected subtree sequence structuresr
347,The approach of phraselevel matching for parse trees and thicket phrase matching for parse thickets turns out to be much more efficient than graph based approaches including graph kernels Instead of considering the space of all possible subgraphs we consider paths in trees and graphs which correspond to linguistic phrases or to phrases merged according to intersentence relations of the discourse We do not consider parts of trees or thickets which correspond neither to a phrase of parse tree nor to a thicket phrase of thicket This is due to the observation that such subtrees and subgraphs are incomplete redundant or noisy features to rely on conducting learning r
348,To estimate the complexity of generalization of two parse thickets let us consider an average case with five sentences in each paragraph and words in each sentence Such thickets have on average phrases per sentence intersentence arcs which give us up to thicket phrases each Hence for such parse thickets we have to generalize up to linguistic phrases and thicket phrases of the first thicket against the set of similar size for the second thicket Taking into account a separate generalization of noun and verb phrases this average case consists of   generalizations followed by the subsumption checks Each phrase generalization is based on up to string comparisons taking an average size of phrase as words Hence on average the parse thicket generalization includes operations Since a string comparison takes a few microseconds thicket generalization takes on average milliseconds without use of index However in an industrial search application where phrases are stored in an inverse index the generalization operation can be completed in constant time irrespectively of the size of index Lin  In case of mapreduce implementation Lin&Dyer  of generalization operation for example using Cascading framework the time complexity becomes constant with the size of candidate search results to be reranked Dean r
349,The author is grateful to Sergey Kuznetsov Dmitry Ilvovsky Fedor Strok Boris Kovalerchuk Daniel Usikov for the fruitful discussion and help in preparation of this manuscriptr
350,Bhasker B K Srikumar  Recommender Systems in ECommerce CUP ISBN r
351,Bichindaritz Isabelle Sarada Akkineni Concept mining for indexing medical literature Engineering Applications of Artificial Intelligence Volume  Issue  June  pp  httpdxdoiorgjengappair
352,Bron Coen; Kerbosch Joep  Algorithm  finding all cliques of an undirected graph Commun ACM ACM  r
353,Bunke H GraphBased Tools for Data Mining and Machine Learning Machine learning and data mining in pattern recognition Lecture Notes in Computer Science  Volume   r
354,Bunke H  P  Foggia  C Guidobaldi C Sansone  and  M Vento A comparison of algorithms for maximum common  subgraph on randomly connected graphs Structural Syntactic and Statistical Pattern Recognition pages  r
355,Byun H SeongWhan Lee  Applications of Support Vector Machines for Pattern Recognition A Survey In Proceedings of the First International Workshop on Pattern Recognition with Support Vector Machines SVM  SeongWhan Lee and Alessandro Verri Eds SpringerVerlag London UK UK r
356,Collins M and Duffy N  Convolution kernels for natural language In Proceedings of NIPS r
357,Conte D P  Foggia  and  M Vento Challenging complexity of maximum common  subgraph detection algorithms  A performance analysis  of three algorithms on a wide database of graphs Journal of Graph Algorithms  and  Applications   r
358,Conte D P Foggia C Sansone and M Vento Thirty years of graph matching in pattern recognition International Journal of Pattern Recognition and Artificial Intelligence Vol  No  r
359,Dan Gusfield  Algorithms on Strings Trees and Sequences Cambridge University Press Cambridge UKr
360,Daniel Jurafsky James H Martin Speech and Language Processing An Introduction to Natural Language Processing Computational Linguistics and Speech Recognition r
361,Dean Jeff Challenges in Building LargeScale Information Retrieval Systems researchgooglecompeoplejeffWSDMkeynotepdf r
362,Domingos P and Poon H Unsupervised Semantic Parsing In Proceedings of the Conference on Empirical Methods in Natural Language Processing  Singapore ACLr
363,Ehrlich HC Rarey M Maximum common subgraph isomorphism algorithms and their applications in molecular science review Wiley Interdisciplinary Reviews Computational Molecular Science  vol  pp r
364,Finn VK  On the synthesis of cognitive procedures and the problem of induction NTI Series  N pp r
365,Fukunaga K Introduction to statistical pattern recognition d ed Academic Press Professional Inc San Diego CA r
366,Furukawa K  From Deduction to Induction Logical Perspective The Logic Programming Paradigm In Apt KR Marek VW Truszczynski M Warren DS Eds Springerr
367,Galitsky B Natural Language Question Answering System Technique of Semantic Headers Advanced Knowledge International Australia r
368,Galitsky B  Josep Lluis de la Rosa Gábor Dobrocsi Inferring the semantic properties of sentences by mining syntactic parse trees Data & Knowledge Engineering Volume  November  r
369,Galitsky B Daniel Usikov Sergei O Kuznetsov Parse Thicket Representations for Answering Multisentence questions h International Conference on Conceptual Structures ICCS r
370,Galitsky B Kuznetsov S Learning communicative actions of conflicting human agents J Exp Theor Artif Intell   r
371,Galitsky B G Dobrocsi JL de la Rosa Kuznetsov SO From Generalization of Syntactic Parse Trees to Conceptual Graphs in M Croitoru S Ferré D Lukose Eds Conceptual Structures From Information to Intelligence h International Conference on Conceptual Structures ICCS  Lecture Notes in Artificial Intelligence vol  pp r
372,Galitsky B Gabor Dobrocsi Josep Lluís de la Rosa Sergei O Kuznetsov Using Generalization of Syntactic Parse Trees for Taxonomy Capture on the Web h International Conference on Conceptual Structures  ICCS   r
373,Galitsky B Content Inversion for User Searches and Product Recommendation Systems and Methods US Patent Application eBay number  r
374,Galitsky B Machine Learning of Syntactic Parse Trees for Search and Classification of Text Engineering Applications of Artificial Intelligence  httpdxdoiorgjengappair
375,Galitsky B MP González CI Chesñevar A novel approach for classifying customer complaints through graphs similarities in argumentative dialogue Decision Support Systems    r
376,Ganter B Kuznetsov SO Pattern Structures and Their Projections In Conceptual Structures Broadening the Base Lecture Notes in Computer Science Volume   pp r
377,Ganter B and Sergei O Kuznetsov Pattern Structures and Their Projections ICCS   r
378,Gildea D   Loosely treebased alignment for machine translation In Proceedings of the h Annual Conference of the Association for Computational Linguistics ACL pp  Sapporo Japanr
379,Haussler D  Convolution kernels on discrete structuresr
380,Heeyoung Lee Angel Chang Yves Peirsman Nathanael Chambers Mihai Surdeanu and Dan Jurafsky Deterministic coreference resolution based on entitycentric precisionranked rules Computational Linguistics  r
381,HennigThurau Thorsten André Marchand and Paul Marx  Can Automated Group Recommender Systems Help Consumers Make Better Choices Journal of Marketing  r
382,Hensman S and Dunnion J Automatically building conceptual graphs using VerbNet and WordNet International Symposium on information and Communication Technologies Las Vegas Nevada June   ACM International Conference Proceeding Series vol  Trinity College Dublin pp r
383,Iwashita Motoi Shinsuke Shimogawa Ken Nishimatsu Semantic analysis and classification method for customer enquiries in telecommunication services Engineering Applications of Artificial Intelligence Volume  Issue  December  Pages  httpdxdoiorgjengappair
384,Kalervo  Jarvelin Jaana Kekalainen Cumulated gainbased evaluation of IR techniques ACM Transactions on Information Systems   r
385,Kapoor S and H Ramesh “Algorithms for Enumerating All Spanning Trees of Undirected and Weighted Graphs SIAM J Computing vol  pp  r
386,Kann V On the Approximability of the Maximum Common Subgraph Problem In STACS  Alain Finkel and Matthias Jantzen Eds SpringerVerlag London UK UK  r
387,Karp Richard M  Reducibility among combinatorial problems in Miller R E; Thatcher J W Complexity of Computer Computations New York Plenum pp  r
388,Kim JungJae Piotr Pezik and Dietrich RebholzSchuhmann MedEvi Retrieving textual evidence of relations between biomedical concepts from Medline Bioinformatics Volume  Issue pp  r
389,Koch  I  Enumerating all connected maximal common  subgraphs in two graphs Theoretical Computer Science   r
390,Kohavi Ron A Study of CrossValidation and Bootstrap for Accuracy Estimation and Model Selection International Joint Conference on Artificial Intelligence IJCAI r
391,Lehrer Adrienne  Semantic Fields and Lexical Structure Amsterdam Benjaminsr
392,Lin J and Chris Dyer DataIntensive Text Processing with MapReduce Morgan & Claypool Publishers r
393,Lin J DataIntensive Text Processing with MapReduce intoolgithubioMapReduceAlgorithmsMapReducebookfinalpdf  r
394,Le HT and Abeysinghe G  ‘A Study to Improve the Efficiency of a Discourse Parsing System’ in A Gelbukh ed Proceedings of h International Conference on Intelligent Text Processing and Computational Linguistics Vol  pp  BerlinSpringerr
395,Lehmann Christian  Directions for interlinear morphemic translations Folia Linguistica r
396,Mann William C Christian M I M Matthiessen and Sandra A Thompson  Rhetorical Structure Theory and Text Analysis Discourse Description Diverse linguistic analyses of a fundraising text ed by W C Mann and S A Thompson Amsterdam John Benjamins r
397,Manning C and Hinrich Schütze Foundations of Statistical Natural Language Processing MIT Press Cambridge MA May r
398,Marcu  Rhetorical Parsing of Unrestricted Texts Computational Linguistics V Nr
399,Marcu D  ‘From Discourse Structures to Text Summaries’ in I Mani and MMaybury eds Proceedings of ACL Workshop on Intelligent Scalable Text Summarization pp  Madrid Spainr
400,Mill JS  A system of logic ratiocinative and inductive Londonr
401,Montaner M; Lopez B; de la Rosa J L June  A Taxonomy of Recommender Agents on the Internet Artificial Intelligence Review  r
402,Moon J W and Moser L  On cliques in graphs Israel J Math  r
403,MoschittiA Efficient Convolution Kernels for Dependency and Constituent Syntactic Trees In Proceedings of the h European Conference on Machine Learning Berlin Germany r
404,Mandow L JL Pérez de la Cruz A heuristic search algorithm with lexicographic goals Engineering Applications of Artificial Intelligence Volume  Issue  December  pp  httpdxdoiorgSXr
405,Palmer Martha Semlink Linking PropBank VerbNet and FrameNet Proceedings of the Generative Lexicon Conference Sept  Pisa Italy GenLex r
406,Plotkin GD A note on inductive generalization In B Meltzer and D Michie editors Machine Intelligence volume  pages  Elsevier NorthHolland New York r
407,Polovina S and John Heaton An Introduction to Conceptual Graphs AI Expert pp   r
408,Punyakanok V Roth D & Yih W  Mapping dependencies trees an application to question answering In Proceedings of AI & Math Florida USAr
409,Punyakanok VRoth D and Yih W The Necessity of Syntactic Parsing for Semantic Role Labeling IJCAIr
410,Robinson JA A machineoriented logic based on the resolution principle Journal of the Association for Computing Machinery  r
411,Richter Michael M The search for knowledge contexts and CaseBased Reasoning Engineering Applications of Artificial Intelligence Volume  Issue  February  Pages  httpdxdoiorgjengappair
412,Kuznetsov SO and MV Samokhin Learning Closed Sets of Labeled Graphs for Chemical Applications In Proc h Conference on Inductive Logic Programming ILP  Lecture Notes in Artificial Intelligence Springer Vol pp r
413,Schilder F  ‘Robust Discourse Parsing via Discourse Markers Topicality and Position’ Natural Language Engineering  r
414,Searle John  Speech acts An essay in the philosophy of language Cambridge England Cambridge Universityr
415,Son JeongWoo TaeGil Noh HyunJe Song SeongBae Park An application for plagiarized source code detection based on a parse tree kernel Engineering Applications of Artificial Intelligence Volume  Issue  September  pp  httpdxdoiorgjengappair
416,Sowa JF Eileen C Way Implementing a Semantic Interpreter Using Conceptual Graphs IBM Journal of Research and Development    r
417,Sowa JF Information Processing in Mind and Machine Reading MA AddisonWesley Publ r
418,Steinberger J  Poesio M  Kabadjov MA  Ježek K Two uses of anaphora resolution in summarization Information Processing & Management Volume  Issue  November  Pages r
419,Sun J; Zhang M; and Tan C Tree Sequence Kernel for Natural Language AAAI r
420,Sun J; Zhang M; and Tan C Exploring syntactic structural features for subtree alignment using bilingual tree kernels In Proceedings of ACL  r
421,Trias i Mansilla A JL de la Rosa i Esteva Asknext An Agent Protocol for Social Search Information Sciences   r
422,Velásquez Juan D Luis E Dujovne Gaston L’Huillier Extracting significant Website Key Objects A Semantic Web mining approach Engineering Applications of Artificial Intelligence Volume  Issue  December  pp  httpdxdoiorgjengappair
423,Vicient Carlos David Sánchez Antonio Moreno An automatic approach for ontologybased feature extraction from heterogeneous textual resources Engineering Applications of Artificial Intelligence Volume  Issue  March  Pages  httpdxdoiorgjengappair
424,Vismara P and  B Valery  Finding Maximum Common  Connected Subgraphs Using Clique Detection or Constraint Satisfaction Algorithms Modelling Computation and  Optimization in Information Systems  and  Management Sciences pages  r
425,Wu Jiangning  Zhaoguo Xuan and Donghua Pan Enhancing text representation for classification tasks with semantic graph structures International Journal of Innovative Computing Information and Control ICIC Volume  Number Br
426,Xiong Hao and Haitao Mi and Yang Liu and Qun Liu ForestBased Semantic Role Labeling in Proc AAAI r
427,Xing Du and Xie Li Accomodating domainindependence—a new approach to the development of general natural language interfaces Engineering Applications of Artificial Intelligence Volume  Issue  March  Pages  r
428,Yan X Han J gSpan GraphBased Substructure Pattern Mining In Proc IEEE Int Conf on Data Mining ICDM’ IEEE Computer Society  r
429,Yang ShihYao and VonWun Soo Extract conceptual graphs from plain texts in patent claimsEngineering Applications of Artificial Intelligence Volume  Issue  June  Pages  httpdxdoiorgjengappair
430,Zhang M; Che W; Zhou G; Aw A; Tan C; Liu T; and Li S  Semantic role labeling using a grammardriven convolution tree kernel IEEE transactions on audio speech and language processing r
431,Bag of Tricks for Image Classification with Convolutional Neural NetworksTong He Zhi Zhang Hang Zhang Zhongyue Zhang Junyuan Xie Mu LiAmazon Web ServiceshtongzhizhzawszhongyuejunyuanxmliamazoncomAbstractMuch of the recent progress made in image classificationresearch can be credited to training procedure refinementssuch as changes in data augmentations and optimizationmethods In the literature however most refinements are either briefly mentioned as implementation details or only visible in source code In this paper we will examine a collection of such refinements and empirically evaluate their impact on the final model accuracy through ablation study Wewill show that by combining these refinements together weare able to improve various CNN models significantly Forexample we raise ResNetxexx topvalidation accuracyfrom  to  on ImageNet We will also demonstrate that improvement on image classification accuracyleads to better transfer learning performance in other application domains such as object detection and semanticsegmentation IntroductionSince the introduction of AlexNet  in  deepconvolutional neural networks have become the dominating approach for image classification Various new architectures have been proposed since then including VGG NiN  Inception  ResNet  DenseNet  andNASNet  At the same time we have seen a steadytrend of model accuracy improvement For example thetopvalidation accuracy on ImageNet  has been raisedfrom  AlexNet to  NASNetAHowever these advancements did not solely come fromimproved model architecture Training procedure refinements including changes in loss functions data preprocessing and optimization methods also played a major role Alarge number of such refinements has been proposed in thepast years but has received relatively less attention In theliterature most were only briefly mentioned as implementation details while others can only be found in source codeIn this paper we will examine a collection of trainingModel FLOPs toptopesNet  G  ResNeXt  G  SEResNet  G  SEResNeXt  G  DenseNet  G  ResNet tricks ours  G  Table  Computational costs and validation accuracy ofvarious models ResNet trained with our xexxtricksxexx is ableto outperform newer and improved architectures trainedwith standard pipelineprocedure and model architecture refinements that improvemodel accuracy but barely change computational complexity Many of them are minor xexxtricksxexx like modifying thestride size of a particular convolution layer or adjustinglearning rate schedule Collectively however they make abig difference We will evaluate them on multiple networkarchitectures and datasets and report their impact to the finalmodel accuracyOur empirical evaluation shows that several tricks leadto significant accuracy improvement and combining themtogether can further boost the model accuracy We compare ResNet after applying all tricks to other relatednetworks in Table  Note that these tricks raises ResNetxexx topvalidation accuracy from  to  onImageNet It also outperforms other newer and improvednetwork architectures such as SEResNeXt In addition we show that our approach can generalize to other networks Inception V and MobileNet  and datasetsPlace We further show that models trained withour tricks bring better transfer learning performance in otherapplication domains such as object detection and semanticsegmentationPaper Outline We first set up a baseline training procedure in Section  and then discuss several tricks that arerXivv csCV  Dec lgorithm Train a neural network with minibatchstochastic gradient descentinitializenetfor epoch
432,imagesb doimagesxexxuniformly random sample b imagesX y xexxpreprocessimagesz xexxforwardnet X`xexxlossz ygradxexxbackward`updatenet gradend forend foruseful for efficient training on new hardware in Section  InSection we review three minor model architecture tweaksfor ResNet and propose a new one Four additional training procedure refinements are then discussed in Section At last we study if these more accurate models can helptransfer learning in Section Our model implementations and training scripts are publicly available in GluonCV  Training ProceduresThe template of training a neural network with minibatch stochastic gradient descent is shown in Algorithm In each iteration we randomly sample b images to compute the gradients and then update the network parametersIt stops after K passes through the dataset All functionsand hyperparameters in Algorithm can be implementedin many different ways In this section we first specify abaseline implementation of Algorithm  Baseline Training ProcedureWe follow a widely used implementation  of ResNetas our baseline The preprocessing pipelines between training and validation are different During training we perform the following steps onebyone Randomly sample an image and decode it into bitfloating point raw pixel values in
433,Randomly crop a rectangular region whose aspect ratiois randomly sampled in
434,then resize the cropped regioninto a bysquare image Flip horizontally with  probability Scale hue saturation and brightness with coefficientsuniformly drawn from
435,Add PCA noise with a coefficient sampled from a normal distribution N  ttpsgithubcomdmlcgluoncvModelBaseline ReferenceTopTopTopTopesNet
436,Table  Validation accuracy of reference implementations and our baseline Note that the numbers for Inception Vare obtained with byinput images Normalize RGB channels by subtracting
437,respectivelyDuring validation we resize each imagexexx shorter edgeto pixels while keeping its aspect ratio Next we cropout the byregion in the center and normalize RGBchannels similar to training We do not perform any randomaugmentations during validationThe weights of both convolutional and fullyconnectedlayers are initialized with the Xavier algorithm  In particular we set the parameter to random values uniformlydrawn from xexx a where a xexxdin  dout Heredin and dout are the input and output channel sizes respectively All biases are initialized to  For batch normalization layers xcexbvectors are initialized to and xcexbvectors toNesterov Accelerated Gradient NAG descent  isused for training Each model is trained for epochs onNvidia VGPUs with a total batch size of  Thelearning rate is initialized to  and divided by at theh h and h epochs Experiment ResultsWe evaluate three CNNs ResNet InceptionV and MobileNet  For InceptionVwe resize theinput images into  We use the ISLVRCdataset which has  million images for training and lasses The validation accuracies are shown in Table  Ascan be seen our ResNetresults are slightly better thanthe reference results while our baseline InceptionVandMobileNet are slightly lower in accuracy due to differenttraining procedure Efficient TrainingHardware especially GPUs has been rapidly evolvingin recent years As a result the optimal choices for manyperformance related tradeoffs have changed For exampleit is now more efficient to use lower numerical precision andlarger batch sizes during training In this section we reviewvarious techniques that enable low precision and large batchhttpsgithubcomdmlcgluoncvtraining without sacrificing model accuracy Some techniques can even improve both accuracy and training speed Largebatch trainingMinibatch SGD groups multiple samples to a minibatch to increase parallelism and decrease communicationcosts Using large batch size however may slow downthe training progress For convex problems convergencerate decreases as batch size increases Similar empirical results have been reported for neural networks  In otherwords for the same number of epochs training with a largebatch size results in a model with degraded validation accuracy compared to the ones trained with smaller batch sizesMultiple works
438,have proposed heuristics to solvethis issue In the following paragraphs we will examinefour heuristics that help scale the batch size up for singlemachine trainingLinear scaling learning rate In minibatch SGD gradient descending is a random process because the examplesare randomly selected in each batch Increasing the batchsize does not change the expectation of the stochastic gradient but reduces its variance In other words a large batchsize reduces the noise in the gradient so we may increasethe learning rate to make a larger progress along the opposite of the gradient direction Goyal et al  reportsthat linearly increasing the learning rate with the batch sizeworks empirically for ResNettraining In particular ifwe follow He et al  to choose  as the initial learning rate for batch size  then when changing to a largerbatch size b we will increase the initial learning rate toxcxbLearning rate warmup At the beginning of the trainingall parameters are typically random values and therefore faraway from the final solution Using a too large learning ratemay result in numerical instability In the warmup heuristicwe use a small learning rate at the beginning and then switchback to the initial learning rate when the training processis stable  Goyal et al  proposes a gradual warmupstrategy that increases the learning rate from to the initiallearning rate linearly In other words assume we will usethe first m batches eg data epochs to warm up and theinitial learning rate is xcexb then at batch i xexxai xexxam we willset the learning rate to be ixcexbmZero xcexb A ResNet network consists of multiple residualblocks each block consists of several convolutional layers Given input x assume blockx is the output for thelast layer in the block this residual block then outputsx  blockx Note that the last layer of a block couldbe a batch normalization BN layer The BN layer firststandardizes its input denoted by xxccx and then performs ascale transformation xcexbxccx xcexb Both xcexband xcexbare learnableparameters whose elements are initialized to  and  respectively In the zero xcexbinitialization heuristic we initializexcexb for all BN layers that sit at the end of a residual blockTherefore all residual blocks just return their inputs mimics network that has less number of layers and is easier totrain at the initial stageNo bias decay The weight decay is often applied to alllearnable parameters including both weights and bias Itxexxequivalent to applying an Lregularization to all parameters to drive their values towards  As pointed out by Jia etal  however itxexx recommended to only apply the regularization to weights to avoid overfitting The no bias decay heuristic follows this recommendation it only appliesthe weight decay to the weights in convolution and fullyconnected layers Other parameters including the biasesand xcexband xcexbin BN layers are left unregularizedNote that LARS  offers layerwise adaptive learningrate and is reported to be effective for extremely large batchsizes beyond  While in this paper we limit ourselvesto methods that are sufficient for single machine trainingin which case a batch size no more than  often leads togood system efficiency Lowprecision trainingNeural networks are commonly trained with bit floating point FP precision That is all numbers are stored inFPformat and both inputs and outputs of arithmetic operations are FPnumbers as well New hardware howevermay have enhanced arithmetic logic unit for lower precisiondata types For example the previously mentioned NvidiaVoffers TFLOPS in FPbut over TFLOPS inFP As in Table  the overall training speed is accelerated by to times after switching from FPto FPonVDespite the performance benefit a reduced precision hasa narrower range that makes results more likely to be outofrange and then disturb the training progress Micikevicius etal  proposes to store all parameters and activations inFPand use FPto compute gradients At the same timeall parameters have an copy in FPfor parameter updating In addition multiplying a scalar to the loss to betteralign the range of the gradient into FPis also a practicalsolution Experiment ResultsThe evaluation results for ResNetare shown in Table  Compared to the baseline with batch size andFP using a larger batch size and FPreduces thetraining time for ResNetfrom min per epoch to min per epoch In addition by stacking all heuristics forInput stemStage tage tage tage utputInputOutputConv
439,snputMaxPool  sownsamplingResidualResidualConvonv onv onvutputInputInputOutput OutputPath A Path BFigure  The architecture of ResNet The convolutionkernel size output channel size and stride size default is are illustrated similar for pooling layerslargebatch training the model trained with batch sizeand FPeven slightly increased  topaccuracy compared to the baseline modelThe ablation study of all heuristics is shown in Table Increasing batch size from to by linear scalinglearning rate alone leads to a  decrease of the topccuracy while stacking the rest three heuristics bridges thegap Switching from FPto FPat the end of trainingdoes not affect the accuracy Model TweaksA model tweak is a minor adjustment to the network architecture such as changing the stride of a particular convolution layer Such a tweak often barely changes the computational complexity but might have a nonnegligible effecton the model accuracy In this section we will use ResNetas an example to investigate the effects of model tweaks ResNet ArchitectureWe will briefly present the ResNet architecture especially its modules related to the model tweaks For detailedinformation please refer to He et al  A ResNet networkconsists of an input stem four subsequent stages and a finaloutput layer which is illustrated in Figure  The input stemhas a xcx convolution with an output channel of and astride of  followed by a xcx max pooling layer also witha stride of  The input stem reduces the input width andheight by times and increases its channel size to Starting from stage  each stage begins with a downsampling block which is then followed by several residualblocks In the downsampling block there are path A andConvonv sonvConvnputOutputa ResNetBConv InputMaxPool  sOutputConv  sConv b ResNetCConvonv sonv ConvnputOutputAvgPoolc ResNetDFigure  Three ResNet tweaks ResNetB modifies thedownsampling block of Resnet ResNetC further modifiesthe input stem On top of that ResNetD again modifies thedownsampling blockpath B Path A has three convolutions whose kernel sizesare xcx xcxand xcx respectively The first convolutionhas a stride of to halve the input width and height and thelast convolutionxexx output channel is times larger than theprevious two which is called the bottleneck structure PathB uses a xcxconvolution with a stride of to transform theinput shape to be the output shape of path A so we can sumoutputs of both paths to obtain the output of the downsampling block A residual block is similar to a downsamplingblock except for only using convolutions with a stride of One can vary the number of residual blocks in each stageto obtain different ResNet models such as ResNetandResNet where the number presents the number of convolutional layers in the network ResNet TweaksNext we revisit two popular ResNet tweaks we callthem ResNetB and ResNetC respectively We proposea new model tweak ResNetD afterwardsResNetB This tweak first appeared in a Torch implementation of ResNet  and then adopted by multipleworks
440,It changes the downsampling block ofResNet The observation is that the convolution in path Aignores threequarters of the input feature map because ituses a kernel size xcxwith a stride of  ResNetB switchesthe strides size of the first two convolutions in path A asshown in Figure  so no information is ignored Becausethe second convolution has a kernel size xcx the outputshape of path A remains unchangedResNetC This tweak was proposed in Inceptionvoriginally and it can be found on the implementationsModelEfficient BaselineTimeepoch TopTopTimeepoch TopTopesNetmin
441,min  Table  Comparison of the training time and validation accuracy for ResNetbetween the baseline BSwith FPand a more hardware efficient setting BSwith FPHeuristicBSBSopTopTopTopinear scaling
442,FPable  The breakdown effect for each effective trainingheuristic on ResNetof other models such as SENet  PSPNet DeepLabV and ShuffleNetV The observationis that the computational cost of a convolution is quadraticto the kernel width or height A xcx convolution is times more expensive than a xcx convolution So thistweak replacing the xcx convolution in the input stemwith three conservative xcx convolutions which is shownin Figure  with the first and second convolutions havetheir output channel of and a stride of  while the lastconvolution uses a output channelResNetD Inspired by ResNetB we note that the xcxconvolution in the path B of the downsampling block alsoignores  of input feature maps we would like to modifyit so no information will be ignored Empirically we foundadding a xcxaverage pooling layer with a stride of beforethe convolution whose stride is changed to  works wellin practice and impacts the computational cost little Thistweak is illustrated in Figure  Experiment ResultsWe evaluate ResNetwith the three tweaks and settings described in Section  namely the batch size is nd precision is FP The results are shown in Table Suggested by the results ResNetB receives more information in path A of the downsampling blocks and improvesvalidation accuracy by around  compared to ResNet Replacing the xcx convolution with three xcx onesgives another  improvement Taking more informationin path B of the downsampling blocks improves the valiModel params FLOPs TopTopesNet M  G  ResNetB M  G  ResNetC M  G  ResNetD M  G  Table  Compare ResNetwith three model tweaks onmodel size FLOPs and ImageNet validation accuracydation accuracy by another  In total ResNetDimproves ResNetby On the other hand these four models have the samemodel size ResNetD has the largest computational costbut its difference compared to ResNetis within  interms of floating point operations In practice we observedResNetD is only  slower in training throughput compared to ResNet Training RefinementsIn this section we will describe four training refinementsthat aim to further improve the model accuracy Cosine Learning Rate DecayLearning rate adjustment is crucial to the training After the learning rate warmup described in Section  wetypically steadily decrease the value from the initial learning rate The widely used strategy is exponentially decayingthe learning rate He et al  decreases rate at  for every epochs we call it xexxstep decayxexx Szegedy et al decreases rate at  for every two epochsIn contrast to it Loshchilov et al  propose a cosineannealing strategy An simplified version is decreasing thelearning rate from the initial value to by following thecosine function Assume the total number of batches is Tthe warmup stage is ignored then at batch t the learningrate xcexb is computed asxcexb
443,costxcfxxcexb where xcexbis the initial learning rate We call this schedulingas xexxcosinexexx decay
444,EpochLearning Rate Cosine DecayStep Decaya Learning Rate Schedule
445,EpochTopxexxAccuracyCosine DecayStep Decayb Validation AccuracyFigure  Visualization of learning rate schedules withwarmup Top cosine and step schedules for batch size Bottom Topvalidation accuracy curve with regardto the two schedulesThe comparison between step decay and cosine decayare illustrated in Figure  As can be seen the cosine decaydecreases the learning rate slowly at the beginning and thenbecomes almost linear decreasing in the middle and slowsdown again at the end Compared to the step decay thecosine decay starts to decay the learning since the beginningbut remains large until step decay reduces the learning rateby  which potentially improves the training progress Label SmoothingThe last layer of a image classification network is often afullyconnected layer with a hidden size being equal to thenumber of labels denote by K to output the predicted confidence scores Given an image denote by zi the predictedscore for class i These scores can be normalized by thesoftmax operator to obtain predicted probabilities Denoteby q the output of the softmax operator q  softmaxz theprobability for class i qi can be computed byqi expzixexxjexpzj Itxexx easy to see qi > andxexxiqi
446,so q is a validprobability distributionOn the other hand assume the true label of this imageis y we can construct a truth probability distribution to bepi  if i  y and otherwise During training we minimize the negative cross entropy loss`p q  xexxxexxi log pi to update model parameters to make these two probability distributions similar to each other In particular by theway how p is constructed we know `p q  xexxlog py xexxy  logxexxiexpzi The optimal solution is zxexx inf while keeping others small enough In other words itencourages the output scores dramatically distinctive whichpotentially leads to overfittingThe idea of label smoothing was first proposed to trainInceptionv It changes the construction of the trueprobability toqi xexxxcexbif i  yxcexbK xexx otherwisewhere xcexbis a small constant Now the optimal solutionbecomeszxexx logK xexxxexxxcexbxcexb  xcexbif i  yxcexbotherwisewhere xcexbcan be an arbitrary real number This encourages a finite output from the fullyconnected layer and cangeneralize betterWhen xcexb  the gap logK xexxxexxxcexbxcexb will bexexx and as xcexbincreases the gap decreases Specifically whenxcexb K xexxK all optimal zxexx will be identical Figure shows how the gap changes as we move xcexb given K  or ImageNet datasetWe empirically compare the output value from twoResNetD models that are trained with and without label smoothing respectively and calculate the gap betweenthe maximum prediction value and the average of the restUnder xcexb  and K
447,the theoretical gap is around Figure  demonstrate the gap distributions from thetwo models predicting over the validation set of ImageNetIt is clear that with label smoothing the distribution centersat the theoretical value and has fewer extreme values Knowledge DistillationIn knowledge distillation  we use a teacher modelto help train the current model which is called the studentmodel The teacher model is often a pretrained model withhigher accuracy so by imitation the student model is ableto improve its own accuracy while keeping the model complexity the same One example is using a ResNetas theteacher model to help training ResNetDuring training we add a distillation loss to penalizethe difference between the softmax outputs from the teachermodel and the learner model Given an input assume p isthe true probability distribution and z and r are outputs ofthe last fullyconnected layer of the student model and theteacher model respectively Remember previously we use axexx
448,epsGapa Theoretical gap GapDensityyonexexxotsmoothedb Empirical gap from ImageNet validation setFigure  Visualization of the effectiveness of label smoothing on ImageNet Top theoretical gap between zxexx and others decreases when increasing xcexb Bottom The empiricaldistributions of the gap between the maximum predictionand the average of the restnegative cross entropy loss `p softmaxz to measure thedifference between p and z here we use the same loss againfor the distillation Therefore the loss is changed to`p softmaxz  T softmaxrT  softmaxzT where T is the temperature hyperparameter to make thesoftmax outputs smoother thus distill the knowledge of label distribution from teacherxexx prediction Mixup TrainingIn Section  we described how images are augmentedbefore training Here we consider another augmentationmethod called mixup  In mixup each time we randomly sample two examples xi yi and xj  yj Then weform a new example by a weighted linear interpolation ofthese two examplesxxccx xcexbbxi  xexxxcexbbxj  yxccx xcexbbyi  xexxxcexbbyj  where xcexbb xexx  is a random number drawn from theBetaxcexb xcexb distribution In mixup training we only usethe new example xxccx yxccx Experiment ResultsNow we evaluate the four training refinements Weset xcexb  for label smoothing by following Szegedy etal  For the model distillation we use T
449,specifically a pretrained ResNetD model with both cosinedecay and label smoothing applied is used as the teacherIn the mixup training we choose xcexb  in the Beta distribution and increase the number of epochs from tobecause the mixed examples ask for a longer trainingprogress to converge better When combining the mixuptraining with distillation we train the teacher model withmixup as wellWe demonstrate that the refinements are not only limited to ResNet architecture or the ImageNet dataset Firstwe train ResNetD InceptionVand MobileNet on ImageNet dataset with refinements The validation accuracies for applying these training refinements onebyone areshown in Table  By stacking cosine decay label smoothing and mixup we have steadily improving ResNet InceptionVand MobileNet models Distillation works well onResNet however it does not work well on InceptionVnd MobileNet Our interpretation is that the teacher modelis not from the same family of the student therefore hasdifferent distribution in the prediction and brings negativeimpact to the modelTo support our tricks is transferable to other dataset wetrain a ResNetD model on MIT Placesdataset withand without the refinements Results are reported in Table  We see the refinements improve the topaccuracyconsistently on both the validation and test set Transfer LearningTransfer learning is one major downstreaming use caseof trained image classification models In this section wewill investigate if these improvements discussed so far canbenefit transfer learning In particular we pick two important computer vision tasks object detection and semanticsegmentation and evaluate their performance by varyingbase models Object DetectionThe goal of object detection is to locate bounding boxesof objects in an image We evaluate performance usingPASCAL VOC  Similar to Ren et al  we use unionset of VOC trainval and VOC trainval for training and VOC test for evaluation respectively Wetrain FasterRCNN  on this dataset with refinementsfrom Detectron  such as linear warmup and long training schedule The VGGbase model in FasterRCNNis replaced with various pretrained models in the previousdiscussion We keep other settings the same so the gain issolely from the base modelsMean average precision mAP results are reported inTable  We can observe that a base model with a highervalidation accuracy leads to a higher mAP for FasterRNNin a consistent manner In particular the best base modelwith accuracy  on ImageNet leads to the best mAPRefinementsResNetD InceptionVMobileNetTopTopTopTopTopTopfficient
450,Table  The validation accuracies on ImageNet for stacking training refinements one by one The baseline models areobtained from Section Model Val TopAcc Val TopAcc Test TopAcc Test TopAccResNetD Efficient
451,Table  Results on both the validation set and the test set of MIT Places dataset Prediction are generated as statedin Section  ResNetD Efficient refers to ResNetD trained with settings from Section  and ResNetD Bestfurther incorporate cosine scheduling label smoothing and mixupRefinement TopmAPBstandard  Defficient
452,distill w mixup  Table  FasterRCNN performance with various pretrained base networks evaluated on Pascal VOCRefinement TopPixAcc mIoUBstandard
453,Table  FCN performance with various base networks evaluated on ADEat  on VOC which outperforms the standard modelby  Semantic SegmentationSemantic segmentation predicts the category for everypixel from the input images We use Fully ConvolutionalNetwork FCN  for this task and train models on theADE  dataset Following PSPNet  and Zhang etal  we replace the base network with various pretrained models discussed in previous sections and apply dilation network strategy
454,on stageand stage Afully convolutional decoder is built on top of the base network to make the final predictionBoth pixel accuracy pixAcc and mean intersection overunion mIoU are reported in Table  In contradictionto our results on object detection the cosine learning rateschedule effectively improves the accuracy of the FCN performance while other refinements provide suboptimal results A potential explanation to the phenomenon is thatsemantic segmentation predicts in the pixel level Whilemodels trained with label smoothing distillation and mixupfavor soften labels blurred pixellevel information may beblurred and degrade overall pixellevel accuracy ConclusionIn this paper we survey a dozen tricks to train deepconvolutional neural networks to improve model accuracyThese tricks introduce minor modifications to the modelarchitecture data preprocessing loss function and learning rate schedule Our empirical results on ResNetInceptionVand MobileNet indicate that these tricks improve model accuracy consistently More excitingly stacking all of them together leads to a significantly higher accuracy In addition these improved pretrained models showstrong advantages in transfer learning which improve bothobject detection and semantic segmentation We believe thebenefits can extend to broader domains where classificationbase models are favoredReferences L Chen G Papandreou F Schroff and H Adam Rethinking atrous convolution for semantic image segmentation CoRR abs
455,LC Chen G Papandreou I Kokkinos K Murphy andA L Yuille Deeplab Semantic image segmentation withdeep convolutional nets atrous convolution and fully connected crfs IEEE transactions on pattern analysis and machine intelligence xexx
456,M Everingham L Van Gool C K I Williams J Winnand A Zisserman The PASCAL Visual Object ClassesChallenge VOC Results httpwwwpascalnetworkorgchallengesVOCvocworkshopindexhtml B Ginsburg I Gitman and Y You Large batch training ofconvolutional networks with layerwise adaptive rate scaling  R Girshick I Radosavovic G Gkioxari P Dollaxccxand K He Detectron httpsgithubcomfacebookresearchdetectron
457,X Glorot and Y Bengio Understanding the difficulty oftraining deep feedforward neural networks In Proceedingsof the thirteenth international conference on artificial intelligence and statistics pages xexx
458,P Goyal P Dollaxccx R B Girshick P NoordhuisL Wesolowski A Kyrola A Tulloch Y Jia and K HeAccurate large minibatch SGD training imagenet in hourCoRR abs
459,S Gross and M Wilber Training and investigating residualnets httptorchchblogresnetshtml
460,K He X Zhang S Ren and J Sun Deep residual learning for image recognition In Proceedings of the IEEE conference on computer vision and pattern recognition pagesxexx
461,G Hinton O Vinyals and J Dean Distilling the knowledgein a neural network arXiv preprint arXiv  A G Howard M Zhu B Chen D Kalenichenko W WangT Weyand M Andreetto and H Adam Mobilenets Efficient convolutional neural networks for mobile vision applications arXiv preprint arXiv
462,J Hu L Shen and G Sun Squeezeandexcitation networks arXiv preprint arXiv
463,G Huang Z Liu L van der Maaten and K Q Weinberger Densely connected convolutional networks In EEE Conference on Computer Vision and Pattern Recognition CVPR pages xexx IEEE
464,X Jia S Song W He Y Wang H Rong F Zhou L XieZ Guo Y Yang L Yu et al Highly scalable deep learningtraining system with mixedprecision Training imagenet infour minutes arXiv preprint arXiv
465,A Krizhevsky I Sutskever and G E Hinton Imagenetclassification with deep convolutional neural networks InAdvances in neural information processing systems pagesxexx
466,M Lin Q Chen and S Yan Network in network arXivpreprint arXiv
467,J Long E Shelhamer and T Darrell Fully convolutionalnetworks for semantic segmentation In Proceedings of theIEEE conference on computer vision and pattern recognition pages xexx
468,I Loshchilov and F Hutter SGDR stochastic gradient descent with restarts CoRR abs
469,P Micikevicius S Narang J Alben G Diamos E ElsenD Garcia B Ginsburg M Houston O KuchaevG Venkatesh et al Mixed precision training arXiv preprintarXiv
470,Y E Nesterov A method for solving the convex programming problem with convergence rate o kxcbx In DoklAkad Nauk SSSR volume  pages xexx
471,HT Z Ningning Ma Xiangyu Zhang and J Sun Shufflenetv Practical guidelines for efficient cnn architecture designarXiv preprint arXiv
472,S Ren K He R Girshick and J Sun Faster rcnn Towardsrealtime object detection with region proposal networks InAdvances in neural information processing systems pagesxexx
473,O Russakovsky J Deng H Su J Krause S SatheeshS Ma Z Huang A Karpathy A Khosla M Bernsteinet al Imagenet large scale visual recognition challengeInternational Journal of Computer Vision xexx
474,K Simonyan and A Zisserman Very deep convolutional networks for largescale image recognition CoRRabs
475,S L Smith PJ Kindermans C Ying and Q V Le Donxexxdecay the learning rate increase the batch size arXivpreprint arXiv
476,C Szegedy V Vanhoucke S Ioffe J Shlens and Z WojnaRethinking the inception architecture for computer visionCoRR abs
477,S Xie R Girshick P Dollaxccx Z Tu and K He Aggregatedresidual transformations for deep neural networks In Computer Vision and Pattern Recognition CVPR IEEEConference on pages xexx IEEE
478,F Yu and V Koltun Multiscale context aggregation by dilated convolutions arXiv preprint arXiv  H Zhang M Cissexccx Y N Dauphin and D LopezPaz mixup Beyond empirical risk minimization CoRRabs
479,H Zhang K Dana J Shi Z Zhang X Wang A Tyagi andA Agrawal Context encoding for semantic segmentationIn The IEEE Conference on Computer Vision and PatternRecognition CVPR June
480,H Zhao J Shi X Qi X Wang and J Jia Pyramid sceneparsing network In Computer Vision and Pattern Recognition CVPR IEEE Conference on pages xexxIEEE
481,ttpsgithubcomfacebookresearchdetectronhttpsgithubcomfacebookresearchdetectron B Zhou A Lapedriza A Khosla A Oliva and A TorralbaPlaces A million image database for scene recognitionIEEE transactions on pattern analysis and machine intelligence
482,B Zhou H Zhao X Puig S Fidler A Barriuso and A Torralba Scene parsing through ade dataset In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
483,B Zoph V Vasudevan J Shlens and Q V Le Learning transferable architectures for scalable image recognitionCoRR abs
484,Instructions for compiling commercial and inherently governmental FTE inventoriesr
485,Agencies will use this spreadsheet to compile their commercial and inherently governmentalr
486,FTE inventories in accordance with Office of Management and Budget OMB Memorandumr
487,These instructions describe the contents of each of the seven worksheets in this spreadsheetr
488,Agencies must complete two of the worksheets  Contact Information and  Inventoryr
489,Once agencies have completed and reviewed their inventories they must  send the completedr
490,spreadsheet to OMB in accordance with OMB Memorandum M  Agencies mustr
491,NOT alter the format of this spreadsheetworkbookr
492,This worksheet is provided for your information cannot be updated by you and containsr
493,agency and bureau codes currentyear direct reimbursable and total FTEs by agency andorr
494,bureau and other descriptive information  The FTE levels were provided by the agencies andr
495,This worksheet is provided for your information cannot be updated by you and contains ar
496,complete list of activity function codes and titlesr
497,This worksheet is provided for your information is based on information provided by the USr
498,Postal Service can and should be updated by you and contains a list of city namesr
499,You should retain only cities where your FTEs work and delete other cities  If a city namer
500,not listed or an installation is required you can turn off the validation function for that cellr
501,and enter as appropriate  If you cannot see all the city codes in the drop down it may ber
502,due to a lack of memory  See tab for a complete list of city codesr
503,This worksheet is provided for your information can and should be updated by you andr
504,contains lists of agencybureau codes name prefixes eg Mr Mrs and suffixes eg Jrr
505,This worksheet contains a list of agencybureau codes used in executive branch agencies  Your
506,should only keep the agencybureau codes that you report and delete all other agencybureaur
507,This worksheet is provided for you to enter contact information for each bureau  You mustr
508,provide at least one contact for each bureau  You should also provide additional contacts inr
509,the event that the primary contact cannot be reachedr
510,You must provide the following information for each agencybureau  Agencybureau coder
511,Organizational unit name or abbreviation  Last Name  First Name  Prefix isr
512,optional  Suffix is optional  Email address and  Phone  The phone number mustr
513,include area code and when possible should be formatted as r
514,Agencies must NOT alter the format of this worksheet  For example you may NOT add newr
515,columns or change the order of columns  If you find it convenient you may remove the dropr
516,down menus but please note that the values you enter must agree with the content of theser
517,This worksheet is provided for you to enter inventory informationr
518,You must provide the following information  a unique sequence number  Agencybureaur
519,code  Organizational unit name or abbreviation  State  City  Country  FTEsr
520,activity function code  Status  Reason  Reserved  first year on inventoryr
521,year of cost comparison  CIVFTE savings  Estimated Annual Comparisonr
522,Savings and  year of MEO Reviewr
523,Agencies must provide a unique sequence number for each row in the worksheet  For yourr
524,convenience numbers have been entered for the first rows  If you provide fewer than r
525,rows please delete the sequence number for blank rows  If you provide more than rowsr
526,please make sure that each new row has a unique sequence numberr
527,The purpose of the sequence number is to help departments large agencies and OMB discussr
528,specific entries in the inventory  For example we believe it will be easier to ask a questionr
529,regarding an entry by referring to a single unique sequence number rather than by specifying ther
530,the values in or more columnsr
531,Agencies must compute by agencybureau the total numbers of FTEs in this worksheetr
532,Agencies must compare these totals to the comparable control total in the AgBu_FTEr
533,worksheet  Differences must be explained to OMBr
534,&L&F&A&CPage &P of &N&R&Dr
535,DepartmentsDepartment of AgricultureOffice of the Secretaryr
536,Cooperative State Research Education and Extension Servicer
537,Animal and Plant Health Inspection Servicer
538,Grain Inspection Packers and Stockyards Administrationr
539,National Institute of Standards and Technologyr
540,Department of EducationOffice of Vocational and Adult Educationr
541,Department of EnergyNational Nuclear Security Administrationr
542,Department of Health and Human ServicesFood and Drug Administrationr
543,Centers for Disease Control and Preventionr
544,Substance Abuse and Mental Health Services Administrationr
545,Agency for Healthcare Research and Qualityr
546,Centers for Medicare and Medicaid Servicesr
547,Z Total Department of Health and Human Services r
548,Z Total Department of Homeland Security r
549,Department of Housing and Urban DevelopmentManagement and Administrationr
550,Z Total Department of Housing and Urban Development r
551,Department of the InteriorBureau of Land Managementr
552,Office of Surface Mining Reclamation and Enforcementr
553,United States Fish and Wildlife Servicer
554,Natural Resources Damage Assessment and Restorationr
555,Office of Special Trustee for American Indiansr
556,Z Total Department of the Interior r
557,Bureau of Alcohol Tobacco Firearms and Explosivesr
558,Department of LaborEmployment and Training Administrationr
559,Department of StateAdministration of Foreign Affairsr
560,Department of TransportationOffice of the Secretaryr
561,Alcohol and Tobacco Tax and Trade Bureaur
562,Z Total Department of the Treasury r
563,Z Total Department of Veterans Affairs r
564,Other Defense Civil ProgramsAmerican Battle Monuments Commissionr
565,White House Commission on the National Moment of Rememberancer
566,Z Total Other Defense Civil Programs r
567,International Assistance ProgramsAgency for International Developmentr
568,Other IndependentsAdvisory Council on Historic Preservationr
569,Architectural and Transportation Barriers Compliance Boardr
570,Barry Goldwater Scholarship and Excellence in Education Founr
571,Chemical Safety and Hazard Investigation Boardr
572,Committee for Purchase from People who are Blind or Severelyr
573,Corporation for National and Community Servicer
574,Court of Appeals for Veterans Claimsr
575,Court Services and Offender Supervision Agency for the Distrr
576,ExportImport Bank of the United Statesr
577,Z Total Federal Deposit Insurance Corporation r
578,Federal Financial Institutions Examination Council Appraisalr
579,Federal Mine Safety and Health Review Commissionr
580,Morris K Udall Scholarship and Excellence in National Envirr
581,National Commission on Libraries and Information Sciencer
582,Institute of Museum and Library Servicesr
583,Occupational Safety and Health Review Commissionr
584,Office of Navajo and Hopi Indian Relocationr
585,AManagement and Support to Test and Evaluationr
586,BManagement Headquarters  Personnel Social Action Programsr
587,DLabor Wage and Hour Compliance Reviewsr
588,DLoan Guaranty Benefits and Entitlements Analysisr
589,ESafe Drinking Water Act CompliancePollution Preventionr
590,EOccupational Safety Health and Environmental Compliancer
591,EResource Conservation and Recovery Act CompliancePollution Preventionr
592,FTechnology Transfer and International Cooperative Program Managementr
593,FSystems Acquisition  Research and Development Supportr
594,GCare of Remains of Deceased Personnel & Funeral Servicesr
595,GManagement Headquarters  Community and Family Servicesr
596,GMorale Welfare and Recreation MWR Servicesr
597,HVISN Services & VISN Support Service Centerr
598,HHospital Food Services and Nutritional Carer
599,INonfield Technical Support to Criminal Investigationsr
600,IPersonnel Security Clearances and Background Investigationsr
601,ICriminal Counter Intelligence and Administrative Investigative Servicesr
602,JOrganizational and Intermediate Repair and Maintenance Managementr
603,JTest Measurement and Diagnostic Equipment TMDEr
604,JOther Test Measurement and Diagnostic Equipmentr
605,JSoftware Support for Embedded and Mission Systemsr
606,JTactical Automatic Data Processing Equipment ADPEr
607,JMetal and Other Containers Textiles Tents and Tarpaulinsr
608,JPortable Field Medical and Dental Equipmentr
609,JOrganizational and Intermediate Maintenance and Repair of Other Equipmentr
610,KTest Measurement and Diagnostic Equipment TMDEr
611,KOther Test Measurement and Diagnostic Equipmentr
612,KSoftware Support for Embedded and Mission Systemsr
613,KTactical Automatic Data Processing Equipment ADPEr
614,KMetal and Other Containers Textiles Tents and Tarpaulinsr
615,KPortable Field Medical and Dental Equipmentr
616,KDepot Repair and Maintenance of Other Equipmentr
617,MCombatant Headquarters  Military Department Command Authorityr
618,MOther Operational Command and Control Activitiesr
619,MIntelligence Production Integration and Analytic Toolsr
620,QCivil Works Planning Production and Managementr
621,QMaintenance of Open Waterways for Navigationr
622,QOperation and Maintenance of Locks and Bridgesr
623,QOperation and Maintenance of Hydropower Facilitiesr
624,QOperation and Maintenance of the Washington Aqueductr
625,QOperation and Maintenance of Recreation Areasr
626,RManagement and Support to R&Dr
627,ROperation and Maintenance of Physical Plantr
628,ROther S&T and R&D Management and Support Activitiesr
629,SCollection and Disposal of Trash and Other Refuser
630,SCollection and Disposal of Hazardous Material HAZMATr
631,SOther Building and Housing Management Servicesr
632,SManagement of Law Enforcement Physical Security and Security Guard Operationsr
633,SLaw Enforcement Physical Security and Security Guard Operationsr
634,SSupport Services to Law Enforcement Physical Security and Security Guardr
635,SOther Law Enforcement Physical Security and Security Guard Operationsr
636,SElectrical Plant and Distribution Systems Operation and Maintenancer
637,SHeating Plant and Distribution Systems Operation and Maintenancer
638,SWater Plant and Distribution Systems Operation and Maintenancer
639,SSewage and Waste Plant and Distribution Systems Operation and Maintenancer
640,SAirConditioning and Cold Storage Plant and Distribution Systems Operation andr
641,SIncinerator Plant and Sanitary Fill Operationsr
642,SSupply Warehousing and Distribution Services Managementr
643,SContractorOperated Parts Stores & Civil Engineering Supply Storesr
644,SOther Utility Plant and Distribution Systems Operation and Maintenancer
645,TDistribution of Petroleum Oil and Lubricant Productsr
646,TDistribution of Liquid Gaseous and Chemical Productsr
647,TPreparation Demilitarization and Disposal of Excess and Surplus Inventoryr
648,TSystems Engineering and Installation of Communications Systemsr
649,TPreparation and Disposal of Excess and Surplus Propertyr
650,TTraining Aids Devices and Simulator Supportr
651,UManagement Headquarters  Military Education and Trainingr
652,UMilitary Institutional Education and Training Managementr
653,UTraining Development and Support for Military Education and Trainingr
654,UOther Military Education and Training Activitiesr
655,UManagement Headquarters  Civilian Education and Trainingr
656,UManagement of Civilian Institutional Training Education and Developmentr
657,UCivil Works Training Education and Developmentr
658,UOther Civilian Training Education and Developmentr
659,WManagement Headquarters  Communications Computing and Informationr
660,WComputing Services and Data Base Managementr
661,WSystems Design Development and Programming Servicesr
662,XProducts Made From Fabric or Similar Materialsr
663,XPreparation of Food and Bakery Productsr
664,XRope Cordage and Twine Products; Chains and Metal Cable Productsr
665,YManagement Headquarters  Defense Direction and Policy Integrationr
666,YManagement Headquarters  Joint Staff Direction of the Armed Forcesr
667,YOther Force Management and General Support Activitiesr
668,YManagement Headquarters  Operation Planning and Controlr
669,YNational Mobilization and Emergency Preparedness Managementr
670,YManagement Headquarters  Foreign Military Sales and Security Assistancer
671,YForeign Military Sales and Security Assistance Program Managementr
672,YSupport External to DoD  Not Identifiedr
673,YPublic Affairs Program Activities and Operationsr
674,YPublic Works and Real Property Maintenance Program Managementr
675,YPersonnel Community Activities and Manpower Program Managementr
676,YVisual Information Program Activities and Operationsr
677,YIdentifying and Developing ConsumerCustomer Information Servicesr
678,ZCorps of Engineers Program and Project Managementr
679,ZManagement of Major Construction of Real Propertyr
680,ZTitle Outgranting and Disposal of Real EstateReal PropertyNational Projectsr
681,ZTitle Outgranting and Disposal of Real EstateReal PropertyLocal Projectsr
682,ZOther Real Property Program and Project Management Activitiesr
683,ZMinor Construction Maintenance and Repair of Family Housing and Structuresr
684,ZMinor Construction Maintenance and Repair of Buildings and Structures Other than Family Housingr
685,ZMaintenance and Repair of Grounds and Surfaced Areasr
686,ZMaintenance and Repair of Railroad Facilitiesr
687,ZMaintenance and Repair of Waterways and Waterfront Facilitiesr
688,ZMaintenance Repair and Minor Construction of Other Real Propertyr
689,C O ENL PERS MGMT CENr
690,CHURCH OF JESUS CHRIST OF LDr
691,IRVING PARK RD P&D CENTERr
692,SO BAPT RADIO AND TV COMMr
693,UNC A CHAPEL HILL SCHLS ADMr
694,WILFORD HALL U S A F HOSPr
695,SeqTotalActivityforFirst YearYear ofCIVFTEEst Ann CostYear ofr
696,NoAgy_BurAbbreviationStateCityCountryFTEsFct CodeStatusReasonFuture UseOn InventoryCost CompareSavingsComp SavingsMEO Reviewr
697,&C&MS Sans SerifBold&UDepartment of State Inherently Governmental FTE Inventory Worksheetr
698,&L&F&A&CPage &P of &N&R&D
699,Instructions for compiling commercial and inherently governmental FTE inventoriesr
700,Agencies will use this spreadsheet to compile their commercial and inherently governmentalr
701,FTE inventories in accordance with Office of Management and Budget OMB Memorandum r
702,These instructions describe the contents of each of the seven worksheets in this spreadsheet r
703,Agencies must complete two of the worksheets  Contact Information and  Inventory r
704,Once agencies have completed and reviewed their inventories they must  send the completed r
705,spreadsheet to OMB in accordance with OMB Memorandum M  Agencies mustr
706,NOT alter the format of this spreadsheetworkbookr
707,This worksheet is provided for your information cannot be updated by you and containsr
708,agency and bureau codes currentyear direct reimbursable and total FTEs by agency andor r
709,bureau and other descriptive information  The FTE levels were provided by the agencies and r
710,This worksheet is provided for your information cannot be updated by you and contains a r
711,complete list of activity function codes and titles  r
712,This worksheet is provided for your information is based on information provided by the US r
713,Postal Service can and should be updated by you and contains a list of city names r
714,You should retain only cities where your FTEs work and delete other cities  If a city name r
715,not listed or an installation is required you can turn off the validation function for that cellr
716,and enter as appropriate  If you cannot see all the city codes in the drop down it may be r
717,due to a lack of memory  See tab for a complete list of city codesr
718,This worksheet is provided for your information can and should be updated by you andr
719,contains lists of agencybureau codes name prefixes eg Mr Mrs and suffixes eg Jrr
720,This worksheet contains a list of agencybureau codes used in executive branch agencies  You r
721,should only keep the agencybureau codes that you report and delete all other agencybureaur
722,This worksheet is provided for you to enter contact information for each bureau  You must r
723,provide at least one contact for each bureau  You should also provide additional contacts in r
724,the event that the primary contact cannot be reachedr
725,You must provide the following information for each agencybureau  Agencybureau code r
726,Organizational unit name or abbreviation  Last Name  First Name  Prefix is r
727,optional  Suffix is optional  Email address and  Phone  The phone number must r
728,include area code and when possible should be formatted as r
729,Agencies must NOT alter the format of this worksheet  For example you may NOT add new r
730,columns or change the order of columns  If you find it convenient you may remove the dropr
731,down menus but please note that the values you enter must agree with the content of theser
732,This worksheet is provided for you to enter inventory informationr
733,You must provide the following information  a unique sequence number  Agencybureau  r
734,code  Organizational unit name or abbreviation  State  City  Country  FTEsr
735,activity function code  Status  Reason  Reserved  first year on inventoryr
736,year of cost comparison  CIVFTE savings  Estimated Annual Comparison r
737,Savings and  year of MEO Reviewr
738,Agencies must provide a unique sequence number for each row in the worksheet  For your    r
739,convenience numbers have been entered for the first rows  If you provide fewer than r
740,rows please delete the sequence number for blank rows  If you provide more than rowsr
741,please make sure that each new row has a unique sequence number  r
742,The purpose of the sequence number is to help departments large agencies and OMB discuss r
743,specific entries in the inventory  For example we believe it will be easier to ask a questionr
744,regarding an entry by referring to a single unique sequence number rather than by specifying ther
745,the values in or more columnsr
746,down menus but please note that the values you enter must agree with the content of these r
747,Agencies must compute by agencybureau the total numbers of FTEs in this worksheet  r
748,Agencies must compare these totals to the comparable control total in the AgBu_FTEr
749,worksheet  Differences must be explained to OMBr
750,Departments                 Department of Agriculture                                   Office of the Secretary                                         r
751,Cooperative State Research Education and Extension Service    r
752,Animal and Plant Health Inspection Service                      r
753,Grain Inspection Packers and Stockyards Administration         r
754,National Institute of Standards and Technology                  r
755,Department of DefenseMilitary                             Operation and Maintenance                                       r
756,Department of Education                                     Office of Vocational and Adult Education                        r
757,Department of Energy                                        National Nuclear Security Administration                        r
758,Department of Health and Human Services                     Food and Drug Administration                                    r
759,Centers for Disease Control and Prevention                      r
760,Substance Abuse and Mental Health Services Administration       r
761,Agency for Healthcare Research and Quality                      r
762,Centers for Medicare and Medicaid Services                      r
763,Z   Total Department of Health and Human Services r
764,Department of Homeland Security                             Departmental Management                                         r
765,Z   Total Department of Homeland Security r
766,Department of Housing and Urban Development                 Management and Administration                                   r
767,Z   Total Department of Housing and Urban Development r
768,Department of the Interior                                  Bureau of Land Management                                       r
769,Office of Surface Mining Reclamation and Enforcement            r
770,United States Fish and Wildlife Service                         r
771,Natural Resources Damage Assessment and Restoration             r
772,Office of Special Trustee for American Indians                  r
773,Z   Total Department of the Interior r
774,Bureau of Alcohol Tobacco Firearms and Explosives            r
775,Department of Labor                                         Employment and Training Administration                          r
776,Department of State                                         Administration of Foreign Affairs                               r
777,Department of Transportation                                Office of the Secretary                                         r
778,Department of the Treasury                                  Departmental Offices                                            r
779,Alcohol and Tobacco Tax and Trade Bureau                        r
780,Z   Total Department of the Treasury r
781,Department of Veterans Affairs                              Medical Programs                                                r
782,Z   Total Department of Veterans Affairs r
783,Other Defense Civil Programs                                American Battle Monuments Commission                            r
784,White House Commission on the National Moment of Rememberance   r
785,Z   Total Other Defense Civil Programs r
786,General Services Administration                             Real Property Activities                                        r
787,International Assistance Programs                           Agency for International Development                            r
788,Other IndependentsAdvisory Council on Historic Preservation                   r
789,Architectural and Transportation Barriers Compliance Board  r
790,Barry Goldwater Scholarship and Excellence in Education Founr
791,Chemical Safety and Hazard Investigation Board              r
792,Committee for Purchase from People who are Blind or Severelyr
793,Corporation for National and Community Service              r
794,Court of Appeals for Veterans Claims                        r
795,Court Services and Offender Supervision Agency for the Distrr
796,ExportImport Bank of the United States                     r
797,Federal Deposit Insurance Corporation                       Bank Insurance                                                  r
798,Z   Total Federal Deposit Insurance Corporation r
799,Federal Financial Institutions Examination Council Appraisalr
800,Federal Mine Safety and Health Review Commission            r
801,Morris K Udall Scholarship and Excellence in National Envirr
802,National Commission on Libraries and Information Science    r
803,Institute of Museum and Library Services                    r
804,Occupational Safety and Health Review Commission            r
805,Office of Navajo and Hopi Indian Relocation                 r
806,AManagement and Support to Test and Evaluationr
807,BManagement Headquarters  Personnel Social Action Programsr
808,DLabor Wage and Hour Compliance Reviewsr
809,DLoan Guaranty Benefits and Entitlements Analysisr
810,ESafe Drinking Water Act CompliancePollution Preventionr
811,EOccupational Safety Health and Environmental Compliancer
812,EResource Conservation and Recovery Act CompliancePollution Preventionr
813,FTechnology Transfer and International Cooperative Program Managementr
814,FSystems Acquisition  Research and Development Supportr
815,GCare of Remains of Deceased Personnel & Funeral Servicesr
816,GManagement Headquarters  Community and Family Servicesr
817,GMorale Welfare and Recreation MWR Servicesr
818,HVISN Services & VISN Support Service Centerr
819,HHospital Food Services and Nutritional Carer
820,INonfield Technical Support to Criminal Investigationsr
821,IPersonnel Security Clearances and Background Investigationsr
822,ICriminal Counter Intelligence and Administrative Investigative Servicesr
823,JOrganizational and Intermediate Repair and Maintenance Managementr
824,JTest Measurement and Diagnostic Equipment TMDEr
825,JOther Test Measurement and Diagnostic Equipmentr
826,JSoftware Support for Embedded and Mission Systemsr
827,JTactical Automatic Data Processing Equipment ADPEr
828,JMetal and Other Containers Textiles Tents and Tarpaulinsr
829,JPortable Field Medical and Dental Equipmentr
830,JOrganizational and Intermediate Maintenance and Repair of Other Equipmentr
831,KTest Measurement and Diagnostic Equipment TMDEr
832,KOther Test Measurement and Diagnostic Equipmentr
833,KSoftware Support for Embedded and Mission Systemsr
834,KTactical Automatic Data Processing Equipment ADPEr
835,KMetal and Other Containers Textiles Tents and Tarpaulinsr
836,KPortable Field Medical and Dental Equipmentr
837,KDepot Repair and Maintenance of Other Equipmentr
838,MCombatant Headquarters  Military Department Command Authorityr
839,MOther Operational Command and Control Activitiesr
840,MIntelligence Production Integration and Analytic Toolsr
841,QCivil Works Planning Production and Managementr
842,QMaintenance of Open Waterways for Navigationr
843,QOperation and Maintenance of Locks and Bridgesr
844,QOperation and Maintenance of Hydropower Facilitiesr
845,QOperation and Maintenance of the Washington Aqueductr
846,QOperation and Maintenance of Recreation Areasr
847,RManagement and Support to R&Dr
848,ROperation and Maintenance of Physical Plantr
849,ROther S&T and R&D Management and Support Activitiesr
850,SCollection and Disposal of Trash and Other Refuser
851,SCollection and Disposal of Hazardous Material HAZMATr
852,SOther Building and Housing Management Servicesr
853,SManagement of Law Enforcement Physical Security and Security Guard Operationsr
854,SLaw Enforcement Physical Security and Security Guard Operationsr
855,SSupport Services to Law Enforcement Physical Security and Security Guardr
856,SOther Law Enforcement Physical Security and Security Guard Operationsr
857,SElectrical Plant and Distribution Systems Operation and Maintenancer
858,SHeating Plant and Distribution Systems Operation and Maintenancer
859,SWater Plant and Distribution Systems Operation and Maintenancer
860,SSewage and Waste Plant and Distribution Systems Operation and Maintenancer
861,SAirConditioning and Cold Storage Plant and Distribution Systems Operation andr
862,SIncinerator Plant and Sanitary Fill Operationsr
863,SSupply Warehousing and Distribution Services Managementr
864,SContractorOperated Parts Stores & Civil Engineering Supply Storesr
865,SOther Utility Plant and Distribution Systems Operation and Maintenancer
866,TDistribution of Petroleum Oil and Lubricant Productsr
867,TDistribution of Liquid Gaseous and Chemical Productsr
868,TPreparation Demilitarization and Disposal of Excess and Surplus Inventoryr
869,TSystems Engineering and Installation of Communications Systemsr
870,TPreparation and Disposal of Excess and Surplus Propertyr
871,TTraining Aids Devices and Simulator Supportr
872,UManagement Headquarters  Military Education and Trainingr
873,UMilitary Institutional Education and Training Managementr
874,UTraining Development and Support for Military Education and Trainingr
875,UOther Military Education and Training Activitiesr
876,UManagement Headquarters  Civilian Education and Trainingr
877,UManagement of Civilian Institutional Training Education and Developmentr
878,UCivil Works Training Education and Developmentr
879,UOther Civilian Training Education and Developmentr
880,WManagement Headquarters  Communications Computing and Informationr
881,WComputing Services and Data Base Managementr
882,WSystems Design Development and Programming Servicesr
883,XProducts Made From Fabric or Similar Materialsr
884,XPreparation of Food and Bakery Productsr
885,XRope Cordage and Twine Products; Chains and Metal Cable Productsr
886,YManagement Headquarters  Defense Direction and Policy Integrationr
887,YManagement Headquarters  Joint Staff Direction of the Armed Forcesr
888,YOther Force Management and General Support Activitiesr
889,YManagement Headquarters  Operation Planning and Controlr
890,YNational Mobilization and Emergency Preparedness Managementr
891,YManagement Headquarters  Foreign Military Sales and Security Assistancer
892,YForeign Military Sales and Security Assistance Program Managementr
893,YSupport External to DoD  Not Identifiedr
894,YPublic Affairs Program Activities and Operationsr
895,YPublic Works and Real Property Maintenance Program Managementr
896,YPersonnel Community Activities and Manpower Program Managementr
897,YVisual Information Program Activities and Operationsr
898,YIdentifying and Developing ConsumerCustomer Information Servicesr
899,ZCorps of Engineers Program and Project Managementr
900,ZManagement of Major Construction of Real Propertyr
901,ZTitle Outgranting and Disposal of Real EstateReal PropertyNational Projectsr
902,ZTitle Outgranting and Disposal of Real EstateReal PropertyLocal Projectsr
903,ZOther Real Property Program and Project Management Activitiesr
904,ZMinor Construction Maintenance and Repair of Family Housing and Structuresr
905,ZMinor Construction Maintenance and Repair of Buildings and Structures Other than Family Housingr
906,ZMaintenance and Repair of Grounds and Surfaced Areasr
907,ZMaintenance and Repair of Railroad Facilitiesr
908,ZMaintenance and Repair of Waterways and Waterfront Facilitiesr
909,ZMaintenance Repair and Minor Construction of Other Real Propertyr
910,C O ENL PERS MGMT CENr
911,CHURCH OF JESUS CHRIST OF LDr
912,IRVING PARK RD P&D CENTERr
913,SO BAPT RADIO AND TV COMMr
914,UNC A CHAPEL HILL SCHLS ADMr
915,WILFORD HALL U S A F HOSPr
916,SeqTotalActivityforFirst YearYear of CIVFTEEst Ann CostYear ofr
917,NoAgy_BurAbbreviationStateCityCountryFTEsFct CodeStatusReasonFuture UseOn InventoryCost CompareSavingsComp SavingsMEO Reviewr
918,&MS Sans SerifBold&UDepartment of State Inherently Governmental FTE Inventory Worksheetr
919,&F&APage &P of &N&D
920,TCM Grids within GFE minutes after issuance from Centersr
921,Pacific Region stated our most important issue and potential IOCbreaker was… r
922,THE NEED FOR TROPICAL CYCLONE INITIALIZATION WIND GRIDSr
923,Reasonably representative of the structure of the tropical cyclone as best as we knowr
924,Communication tests sending TPC grids to PR mostly successfulr
925,FSL tool successfully run at WFO Guam PRH and WFO Honolulur
926,Can only be fully evaluated using a real storm when it comes into either Guam’s or Honolulu’s domainr
927,One big drawback to the TPC tool is the hour resolutionr
928,The Original Goal To give forecasters aid to translating text warnings into hourly forecast for point locations for use in TAFs and determining temporal “breakpoints for determining periods of destructive windsr
929,WFO Guam had warning pointsislands and frequently had more than one tropical cyclone to warn on in their coverage arear
930,Develop a Rankin vortex centered on each interpolated hourly positionr
931,Using this model calculate wind speeds for both points islands and at regularlyspaced gridpointsr
932,Adjust wind speedsdirections by addingsubtracting vector storm movementr
933,Determination of Radius of Maximum Wind RMW  not part of forecast but input to the formular
934,How rapidly does wind speed fall off as one moves away from centerr
935,Variances include spectrum from huge storm down to “midget typhoonsr
936,Inherent dangers with using a highly deterministic approach to describe difficulttopredict tropical cyclone movement and intensityr
937,Koror    Ngulu    Yap      Taipei   Hong Kongr
938,Lat   Lon    Wind      Mvmt         DstncDirctn from naut mir
939,Paper to be presented May at AMS Tropical Conferencer
940,Analyze effect of difference in temporal resolution eg interpolated hr TPC grids to hr vs FSL hrr
941,Analyze effect of differences in spatial resolutionr
942,Not efficient to support two tools other than in a test environmentr
943,UNKRANDLEMANRANDOLPHNCTREES AND POWER LINES DOWN REPORTED BY THE FIRE DEPARTMENT RAHr
944,UNKE RANDLEMANRANDOLPHNCLAW ENFORCEMENT REPORTED AN OUTBUILDING WAS LEVELED ON APPLEWOOD ROAD AND SHINGLES BLOWN OFF A ROOF IN ADDITION NUMEROUS TREES AND POWER LINES HAVE BEEN REPORTED DO RAHr
945,UNKE HIGH POINTGUILFORDNCTROOPER REPORTED TORNADO ON THE GROUND NEAR RIVER ROAD NEAR JAMESTOWN RAHr
946,UNKE GOLDSTONCHATHAMNCSTATE TROOPER REPORTED A TORNADO ON THE GROUND NORTH OF GULF RAHr
947,UNKW WILSONWILSONNCLAW ENFORCEMENT REPORTED A TORNANDO TOUCHDOWN NEAR HIGHWAY AND LLOYD ROAD RAHr
948,UNKRANDLEMANRANDOLPHNCLAW ENFORCEMENT REPORTED OUTBUILDING WAS LEVELED ON APPLEWOOD ROAD RAHr
949,UNKSSW LINWOODJOHNSTONNCLAW ENFORCEMENT REPORTED TORNADO ON THE GROUND AT COVERED BRIDGE ROAD AND THANKSGIVING FIRE ROAD MULTIPLE TREES DOWN IN ROAD RAHr
950,UNKNW WILSONWILSONNCSPOTTERS REPORT TORNADO ON THE GROUND NEAR IAND BLOOMERY ROAD RAHr
951,UNKNW NEW HOPENASHNCTORNADO TOUCHDOWN HIGHWAY ONE HALF MILE WEST OF INTERSTATE  RAHr
952,UNKW NEW HOPEWILSONNCSPOTTER REPORTED BRIEF TOUCHDOWN IN A TOBACCO AND SOYBEAN FIELD NEAR LAMM ROAD AND BLOOMERY ROAD CURRENTLY ALOFT BUT WALL CLOUD STILL ROTATING RAHr
953,UNKNNE SILER CITYCHATHAMNCAN EFTORNADO TRACKED NORTHEAST ALONG JESSE BRIDGES ROAD CROSSING SILK HOPE LIBERTY ROAD DESTROYING AN OUTBUILDINGCAUSING MINOR DAMAGE TO HOMES AND UPROOTING TREES RAHr
954,UNKROSE HILLDUPLINNCLAW ENFORCEMENT REPORTED A TORNADO ON THE GROUND ON HIGHWAY BETWEEN ROSE HILL AND TEACHEY NO DAMAGE OBSERVED MHXr
955,UNKROSE HILLDUPLINNCPOSSIBLE TORNADO REPORTS OF MULTIPLE POWER OUTAGES IN THE ROSE HILL AND TEACHEY AREA MHXr
956,UNKNE FREMONTWAYNENCA LARGE BARN WAS DESTROYED NEAR THE WAYNEWILSON COUNTY LINE IN WAYNE COUNTY ALONG AYCOCK CHURCH ROAD RAHr
957,UNKNNE FREMONTWILSONNCSEVERAL TREES REPORTED AND DOWN AND A BASKETBALL GOAL BLOWN OVER ALONG SOUTH BEAVER DAM ROAD JUST NORTH OF THE WAYNEWILSON COUNTY LINE RAHr
958,UNKNW TURKEYSAMPSONNCA FEW TREES WERE BLOWN DOWN ACROSS OLD WARSAW ROAD RAHr
959,UNKENE ASHEBORORANDOLPHNCONE TREE REPORTED DOWN ACROSS WHITE MEMORIAL ROAD BLOCKING TRAFFIC NEAR RIVER RAT ROAD TIME ESTIMATED BY RADAR RAHr
960,UNKNE SILER CITYCHATHAMNCSEVERAL TREES DOWN ABOUT A MILE NORTHEAST OF SILER CITY ON JESSE BRIDGES ROAD RAHr
961,UNKST DAVIDCOCHISEAZTHREE WOOD UTILITY POLES BLOWN DOWN IN THE CENTER OF THE CITYON STATE ROUTE  TWCr
962,NNE SIOUX CITYWOODBURYIASEVERAL TREES DOWN AND CHIMNEY KNOCKED DOWN FSDr
963,UNKNW ANTHONWOODBURYIAINCH DIAMETER TREE LIMBS DOWN FSDr
964,WNW OTOWOODBURYIATO DIAMETER INCH TREE LIMBS DOWN FSDr
965,Anirban Basu Software Quality Assurance Testing and Metrics PHI Learning r
966,M Fewster and D Graham Software Test Automation Effective use of test execution tools Addison–Wesley r
967,Pressman RS Software Engineering A Practitioners Approach McGrawHill Publishing Company r
968,I Sommerville Software Engineering b ed AddisonWesley r
969,Phadke M Quality Engineering Using Robust Design Pearson Education India r
970,P Jorgensen Software Testing A Craftsman’s Approach CRC Press r
971,B Beizer Software Testing Techniques d ed Van Nostrand Reinhold r
972,Craig Larman Applying UML and patterns Addison Wesley r
973,GJ Myers Csandler TBadgett and TMThomas The art of software Testing d EditionWiley r
974,Dustin Garett Gauf Implementing Automated Software Testing Pearson r
975,ElFar I K and J A Whittaker Modelbased software testing in Encyclopedia of Software Engineering John Wiley & Sons Inc pp r
976,D Kundu D Samanta and R Mall An Approach to Convert XMI Representation of UML x Interaction Diagram into Control Flow Graph in International Scholarly Research Network ISRN Software Engineering Volume r
977,M Sarma D Kundu and R Mall “Automatic test case generation from UML sequence diagram in Proceedings of the h International Conference on Advanced Computing and Communications ADCOM ’ pp  IEEE Computer Society Washington DC USA r
978,C D Nguyen A Marchetto and P Tonella Combining modelbased and combinatorial testing for effective test case generation In Proceedings of the International Symposium on Software Testing and Analysis ISSTA r
979,R Mahmood N Mirzaei and S Malek EvoDroid segmented evolutionary testing of Android apps In Proceedings of the d ACM SIGSOFT International Symposium on Foundations of Software Engineering FSE r
980,A Machiry R Tahiliani and M Naik Dynodroid An input generation system for android apps In Proceedings of the th Joint Meeting on Foundations of Software Engineering ESECFSE  pages  r
981,I Moore Jester a Junit test tester in proceedings of the d International Conference on Extreme Programming and Flexible Processes in Software Engineering Springer r
982,L Deng N Mirzaei P Ammann and J Offutt Towards Mutation Analysis of Android Apps In proceedings of the Eighth International Conference on Software Testing Verification and Validation Workshops ICSTW IEEE r
983,Anbunathan R and Anirban Basu Dataflow test case generation from UML Class diagrams IEEE International Conference on Computational Intelligence and Computing Research ICCIC r
984,Shah SA Shahzad RK Bukhari SS Humayun M “Automated Test Case Generation Using UML Class & Sequence Diagram British Journal of Applied Science & Technology   r
985,Alsmadi I Alkhateeb F Maghayreh E Samarah S and Doush I A “Effective generation of test cases using genetic algorithms and optimization theory Journal of Communication and Computer   r
986,M Shirole A Suthar and R Kumar Generation of Improved Test Cases from UML State Diagram Using Genetic Algorithm in Proceedings of the h India Software Engineering Conference pp  r
987,C Mingsong Q Xiaokang and L Xuandong Automatic test case generation for UML activity diagrams In international workshop on Automation of softwaretest pp  r
988,D Kundu and D Samanta A Novel Approach to Generate Test Cases from UML Activity Diagrams Journal of Object Technology vol  no  pp  r
989,H Kim S Kang J Baik and I Ko “Test Cases Generation from UML Activity Diagrams In Eighth ACIS International Conference on Software Engineering Artificial Intelligence Networking and ParallelDistributed Computing IEEE Qingdao China  r
990,W Linzhang Y Jiesong Y Xiaofeng H Jun L Xuandong and Z Guoliang“Generating Test Cases from UML Activity Diagram based on GrayBox Method In Proceedings of the h AsiaPacific Software Engineering ConferenceAPSEC IEEE Busan Korea  r
991,C Sun B Zhang J Li “TSGen A UML Activity Diagrambased Test Scenario Generation Tool In International Conference on Computational Science and Engineering IEEE Vancouver Canada  r
992,M Chen X Qiu W Xu L Wang J Zhao and X Li UML Activity Diagram Based Automatic Test Case Generation for Java Programs The Computer Journal r
993,PSamuel and Rajib Mall “SlicingBased Test Case Generation from UML Activity Diagrams In ACM SIGSOFT Software Engineering Notes  pp  r
994,HStallbaum AMetzger and KPohl “An Automated Technique for Riskbased Test Case Generation and Prioritization In ACM Proceedings of the d international workshop on Automation of software test pp  r
995,AHettab EKerkouche and AChaoui “A Graph Transformation Approach for Automatic Test Cases Generation from UML Activity Diagrams In ACM Proceedings of the Eighth International C Conference on Computer Science & Software Engineering pp  r
996,MChen PMishra and DKalita “Coveragedriven Automatic Test Generation for UML Activity Diagrams In proceedings of the h ACM Great Lakes symposium on VLSI ppr
997,Flores Pedro and Cheon Yoonsik PWiseGen Generating Test Cases for Pairwise Testing Using Genetic Algorithms Departmental Technical Reports CS Paper r
998,M Shirole M Kommuri and R Kumar Transition Sequence Exploration of UML Activity Diagram using Evolutionary Algorithm in Proceedings of the ISEC  pp  r
999,David E Goldberg Genetic Algorithms in Search Optimization and Machine Learning AddisonWesley r
1000,W Yang M R Prasad and T Xie A greybox approach for automated guimodel generation of mobile applications In Proceedings of the h International Conference on Fundamental Approaches to Software Engineering FASE Berlin Heidelberg  SpringerVerlagr
1001,S Roy Choudhary A Gorla and A Orso Automated Test Input Generation for Android Are We There Yet In Proceeding of the Automated Software Engineering ASE th IEEEACM International Conference on Lincoln NE  pp r
1002,M Shirole and R KumarTesting for Concurrency in UML Diagrams In ACM SIGSOFT Software Engineering Notes  pp  r
1003,H Kim Generating Test Cases from UML Activity Diagrams Master degree Thesis Korea Institute Of Science and Technology r
1004,Anbunathan R and Anirban Basu Automatic Test Generation from UML Sequence Diagrams for Android Mobiles International Journal of Applied Engineering Research Vol  No pp  r
1005,Debasish Kundu Debasis Samanta and Rajib Mall Automatic code generation from unified modelling language sequence diagrams IET Softw  Vol  Iss  pp r
1006,Sunitha Edacheril Viswanathan and Philip Samuel Automatic code generation using unified modeling language activity and sequence models IET Softw  Vol  Iss  pp r
1007,Muhammad Usman and Aamer Nadeem “Automatic Generation of Java Code from UML Diagrams using UJECTOR International Journal of Software Engineering and Its Applications vol  no  pp r
1008,Simon Pickin Claude Jard Thierry J and JeanMarc J “Test Synthesis from UML Models of Distributed Software IEEE Transactions on software Engineering vol  no  pp r
1009,Niaz IA ‘Automatic code generation from UML class and statechart diagrams’ Thesis Report University of Tsukuba Japan r
1010,J Ali and J Tanaka “An Object Oriented Approach to Generate Executable Code from OMTBased Dynamic Model Journal of Integrated Design and Process Science vol  no  pp r
1011,Ruifeng Chen and Huaikou Miao A Selenium based Approach to Automatic Test Script Generation for Refactoring JavaScript Code in IEEEACIS h International Conference on Computer and Information Science ICIS r
1012,Tuomas Pajumen Tommi Takala and Mika Katara “ModelBased Testing a General Purpose KeywordDriven Test Automation Framework International Conference on Software Testing Verification and Validation Workshops r
1013,Tommi Takala Mika Katara and Julian Harty “Experiences of systemlevel modelbased GUI testing of an Android application in Proceedings of the h IEEE International Conference on Software Testing Verification and Validation ICST  Los Alamitos CA USA IEEE Computer Society Mar  pp r
1014,PCosta ACR Paiva and M Nabuco Pattern Based GUI testing for Mobile Applications In Proc of h International Conference on the Quality of Information and Communications Technology QUATIC IEEE Computer Society r
1015,D Amalfitano A R Fasolino P Tramontana N Amatucci Considering Context Events in EventBased Testing of Mobile Applications IEEE Sixth International Conference on Software Testing Verification and Validation Workshops ICSTW r
1016,Anbunathan R and Anirban Basu A Recursive Crawler Algorithm to Detect Crash in Android Application IEEE International Conference on Computational Intelligence and Computing Research ICCIC r
1017,Anbunathan R and Anirban Basu Automation framework for testing Android mobiles International Journal of Computer Applications Vol  No   November r
1018,Anbunathan R and Anirban Basu An Event based Test Automation Framework for Android Mobiles IEEE First International Conference on Contemporary Computing and Informatics IC r
1019,D Amalfitano A R Fasolino P Tramontana A GUI Crawlingbased technique for Android Mobile Application Testing IEEE Fourth International Conference on Software Testing Verification and Validation Workshops ICSTW r
1020,Lu Lu Yulong hong Kai Su Yuping Yan Activity Page based Functional Test Automation for Android Application IEEE Third World Congress on Software Engineering WCSE r
1021,Emanuela G Cartaxo Francisco G O Neto and Patr´ıcia D L Machado Test Case Generation by means of UML Sequence Diagrams and Labeled Transition Systems IEEE r
1022,AVK Shanthi DrGMohan KumarAutomated Test Cases Generation from UML Sequence Diagram International Conference on Software and Computer Applications r
1023,Li BaoLin Li Zhishu Li Qing Chen Yan Hong  Test Case automate Generation from UML Sequence diagram and OCL Expression International Conference on Computational Intelligence and Security  pp r
1024,Monalisa Sarma Debasish Kundu Rajib MallAutomatic Test Case Generation from UML Sequence Diagrams h International Conference on Advanced Computing and Communications r
1025,Qaisar A Malik Dragos¸ Trus¸can Johan LiliusUsing UML Models and Formal Verification in ModelBased Testing h IEEE International Conference and Workshops on Engineering of ComputerBased Systems r
1026,Padma Iyenghar Elke Pulvermueller Clemens WesterkampTowards ModelBased Test Automation for Embedded Systems Using UML and UTP IEEE ETFA r
1027,Vinaya Sawant Dragos¸ Ketan ShahAutomatic Generation of Test Cases from UML Models International Conference on Technology Systems and Management r
1028,Santosh Kumar Swain Durga Prasad Mohapatra Rajib MallTest Case Generation Based on Use case and Sequence Diagram Internatonal Journal of Software Engineering VolNor
1029,F Fraikin and T Leonhardt “SeDiTeC—testing based on sequence diagrams in Proceedings of the IEEE International Conference on Automated Software Engineering ASE ’ pp r
1030,Jean Hartmann Claudio Imoberdorf Michael Meisinger “UMLBased Integration Testing“ Proceedings of the International Symposium on Software Testing and AnalysisPortland Oregon  pp r
1031,J Offutt and A Abdurazik “Generating Tests from UML Specifications Second International Conference on the Unified Modeling Language Springer New York  ppr
1032,W M Ho JM Jquel A L Guennec and F Pennaneac’h“UMLAUT An extendible UML transformation framework in Automated Software Engineering  pp r
1033,T J´eron and P Morel “Test generation derived from modelchecking in CAV ’ Proceedings of the h International Conference onComputer Aided Verification London UK SpringerVerlag pp r
1034,C Jard and T Jeron “Tgv theory principles and algorithmsA tool for the automatic synthesis of conformance test cases for nondeterministic creactive systems Int J Softw Tools Technol Transfvol  no  pp  r
1035,L Bousquet H Martin and J Jzquel “Conformance testing from uml specifications in proceedings of the UMLworkshop Practical UMLBased Rigorous Development Methods Octoberr
1036,F Z M Beyer W Dulz “Automated ttcntest case generation by means of uml sequence diagrams and markov chains in Asian TestSymposium  pp r
1037,S Kansomkeat and W Rivepiboon “Automatedgenerating test case using UML statechart diagrams Proc SAICSIT  ACM pp –  r
1038,Demillo Lipton and Sayward “Hints on Test Data SelectionHelp for the Practicing Programmer Computer   Apr r
1039,P Samuel R Mall AK Bothra Automatic test case generation using unified modeling language UML state diagrams The Institution of Engineering and Technology r
1040,KIM YG HONG HS BAE DH ET AL ‘Test cases generation from UML state diagram’ IEE Proceedings  Software Vol  No  pp  Aug r
1041,Ranjita Swain Vikas Panthi and Durga Prasad Mohapatra Automatic Test case Generation From UML State Chart Diagram International Journal of Computer Applications –  Volume  No March r
1042,Gnesi Stefania Latella Diego and Massink Mieke  Formal testcase generation for UML statecharts Proceedings of the Ninth IEEE International Conference on Engineering Complex Computer Systems Navigating Complexity in the eEngineering Age pp–  r
1043,Joanne M Atlee and John Gannon StateBased Model Checking of EventDriven System Requirements IEEE Transactions on Software Engineering VOL  No  January r
1044,John Joseph Chilenski and Steven P Miller Applicability of modified condition decision coverage to software testing Software Engineering Journal September r
1045,Luqi Hongji Yang and Xiaodong Zhang Constructing an Automated Testing Oracle An Effort to Produce Reliable Software Computer Software and Applications Conference r
1046,Apfelbaum and Larry Automated functional test generation AUTOTESTCON  r
1047,Mark Stephenson Tom Lynch and Steve Walters Using Advanced Tools to Automate the Design Generation and Execution of Formal Qualification Testing AUTOTESTCON r
1048,Peter Savage Steve Waiters and Mark Stephenson Automated Test Methodology for Operational Flight Programs in Proceedings of Aerospace Conference  r
1049,T Savor and RE Seviora An Approach to Automatic Detection of Software Failures in RealTime Systems in Proceedings of RealTime Technology and Applications Symposium  r
1050,A Jeerson Outt Yiwei Xiong and Shaoying Liu Criteria for Generating Specicationbased Tests in Proceedings of Fifth IEEE International Conference on Engineering of Complex Computer Systems r
1051,Peter Fröhlich and Johannes Link Automated Test Case Generation from Dynamic Models in Proceedings of European Conference on Object Oriented Programming r
1052,Diego Latella and Mieke Massink A Formal Testing Framework for UML Statechart Diagrams Behaviours From Theory to Automatic Verification in Proceedings of the h IEEE International Symposium on High Assurance Systems Engineering r
1053,Philippe Chevalley and Pascale ThevenodFosse An Empirical Evaluation of Statistical Testing Designed from UML State Diagrams the Flight Guidance System Case Study in Proceedings of h International Symposium on Software Reliability Engineering r
1054,Khaled ElFakih Anton Kolomeez Svetlana Prokopenko and Nina Yevtushenko Extended Finite State Machine Based Test Derivation Driven By User Defined Faults International Conference on Software Testing Verification and Validation r
1055,Tsun S Chow Testing Software Design Modeled by FiniteState Machines IEEE Transactions On Software Engineering Vol Se No  May r
1056,Xi Wang Liang Guo and Huaikou Miao An Approach to Transforming UML Model to FSM Model for Automatic Testing International Conference on Computer Science and Software Engineering r
1057,Quratulann Farooq Muhammad Zohaib ZIqbal Zafar I Malik and Zafar I Malik A ModelBased Regression Testing Approach for Evolving Software Systems with Flexible Tool Support h IEEE International Conference and Workshops on Engineering of ComputerBased Systems r
1058,Reinhard Hametner Dietmar Winkler Thomas Östreicher Natascha Surnic and Stefan Biffl Selecting UML Models for TestDriven Development along the Automation Systems Engineering Process IEEE Conference on Emerging Technologies and Factory Automation r
1059,Reinhard Hametner Benjamin Kormann Birgit VogelHeuser Dietmar Winkler and Alois Zoitl Test Case Generation Approach for Industrial Automation Systems h International Conference on Automation Robotics and Applications r
1060,Manuj Aggarwal and Sangeeta Sabharwal Test Case Generation from UML State Machine Diagram A Survey Third International Conference on Computer and Communication Technology r
1061,Hyungkeun Song Seokmoon Ryoo and Jin Hyung Kim “An Integrated Test Automation Framework for Testing on Heterogeneous Mobile Platforms IEEE First ACIS International Symposium on Software and Network Engineering r
1062,M E Delamaro A M R Vincenzi and J C Maldonado “A strategy to perform coverage testing of mobile applications In Proceedings of the international workshop on Automation of software test AST  ACM New York NY USA r
1063,I Satoh “A testing framework for mobile computing software IEEE Transactions on Software Engineering  Dec r
1064,JHCho LSLee Automatic Test Data Generation for Datadriven Testing using Abstract Test Script International Journal of Software Engineering and Its Applications Vol  No   r
1065,RRKachewar K model for designing Data Driven Test Automation Frameworks and its Design Architecture “Snow Leopard International Journal of Computer Applications Vol  No  October r
1066,Zhenyu Liu Qiang Chen and Xu Jiang A Maintainability SpreadsheetDriven Regression Test Automation Framework In Proc of IEEE h International Conference on Computational Science and Engineering r
1067,Pekka Laukkanen “DataDriven and KeywordDriven Test Automation Frameworks Master’s thesis submitted in partial fulfillment of the requirements for the degree of Master of Science in Technology Espoo February  r
1068,Sonu Lamba Vinay Rishiwal and Arjun Rana An automated data driven continuos testing framework International Journal of Advanced Technology in Engineering and Science Vol  No  February r
1069,KOREL B ‘Automated software test data generation’IEEE Trans Softw Eng    pp r
1070,Ricardo D F Ferreira João P Faria Ana C R Paiva João P Faria “Test Coverage Analysis of UML State Machines IEEE Third International Conference on Software Testing Verification and Validation Workshops r
1071,Du Qingfeng Dong Xiao “An Improved Algorithm for Basis Path Testing IEEE International Conference on Business Management and Electronic Information BMEI r
1072,Arthur H Watson and Thomas J McCabe “Structured testing a testing methodology using the cyclomatic complexity metric NIST Special Publication September r
1073,T K Wijayasiriwardhane P G Wijayarathna D D Karunarathna “An Automated Tool to Generate Test Cases for Performing Basis Path Testing The International Conference on Advances in ICT for Emerging Regions – ICTer r
1074,T McCabe A Complexity Measure IEEE Transactions on Software Engineering vol  no  pp  December r
1075,D Harel Statecharts A Visual Formalism for Complex Systems Science of Computer Programming Vol  r
1076,Santosh Kumar Swain Durga Prasad Mohapatra Rajib Mall “Test Case Generation Based on State and Activity Models In Journal of Object Technology vol  no   pages r
1077,Mary Jean Harrold and Gregg Rothermel “Performing Data Flow Testing on Classes proc of the second ACM SIGSOFT Symp on the foundation Softw Eng December  pages r
1078,LAClarke APodgueski DRichardson SZeil A comparison of data flow path selection criteria IEEE Transactions on Software Engineering  November r
1079,SRapps and EJWeyuker Selecting software test data using data flow information IEEE Transactions on Software Engineering SE April r
1080,Chartchai Doungsaard Keshav Dahal Alamgir Hossain and Taratip Suwannasart “Test Data Generation from UML State Machine Diagrams using GAs IEEE International Conference on Software Engineering Advances r
1081,Sthamer The Automatic Generation of Software Test Data Using Genetic Algorithms PHD Thesisr
1082,Andreas S Andreou Kypros A Economides and Anastasis A Sofokleous “An automatic software testdata generation scheme based on data flow criteria and genetic algorithms IEEE Seventh International Conference on Computer and Information Technology r
1083,SRapps and EJWeyuker Data flow analysis techniques for test data selection Sixth International Conference on Software Engineering r
1084,Anbunathan R and Anirban Basu Automation framework for test script generation for Android mobile CSI Springer Annual Convention on Digital Life December  in pressr
1085,A M Memon M L Soffa and M E Pollack Coverage criteria for GUI testing In Proceedings of the h European Software Engineering Conference ESEC and h ACM SIGSOFT International Symposium on the Foundations of Software Engineering FSE pages  Sept r
1086,A Memon L Banerjee A Nagarajan GUI rippingreverse engineering of graphical user interfaces for testing Proceedings of the h Working Conference on Reverse Engineering WCRE   IEEE CS Press pp–r
1087,A Memon Martha E Pollack Mary Lou Soffa Hierarchical GUI Test Case Generation Using Automated Planning IEEE Transactions On Software Engineering Vol  No  February r
1088,A M Memon I Banerjee N Hashmi and A Nagarajan DARTA framework for regression testing nightlydaily builds of GUI applications In Proceedings of the International conference on software maintenance  September r
1089,A M Memon and Qing Xie Designing and comparing automated test oracles for GUIbased software applications ACM Transactions on Software Engineering and Methodology ACM Press vol  no  r
1090,Tom Wissink and Carlos Amaro Successful Test Automation for Software Maintenance In Proc of The d IEEE International Conference on Software Maintenance ICSM r
1091,Xulan He Embedded Systems Based Modular Test Automation International Colloquium on Computing Communication Control and Management r
1092,Ashutosh Kumar Jha Development of Test Automation Framework for Testing Avionics Systems h Digital Avionics Systems Conference r
1093,Leckraj Nagowah and Gayeree Sowamber A Novel Approach of Automation Testing on Mobile Devices International Conference on Computer & Information Science ICCIS r
1094,&C&Times New RomanRegular&age &P
1095,IT Project ManagerBusiness AnalystBusiness IntelligenceData warehousingr
1096,I am active in the IoT Open SourceHardware communityr
1097,My  education background combines software and hardwarer
1098,Internet connected objects things working together to solve a business problemr
1099,Has been around for quite a while but only recently has become affordable for personal user
1100,It isn’t coming soon  it is already here and has been so for quite a whiler
1101,Connects billions of sensors and devices from every day consumer objects to industrial equipmentr
1102,Generate collect process and use acquired information to make better decisions r
1103,Smart objects Make things that weren’t meant to talk to each other interact smartlyr
1104,Gartner says the Internet of Things installed base will grow to Billion units by  I want to be well aligned and prepared for thatr
1105,Generate collect process and use acquired information to make decisionsr
1106,Information is inferred from data in the process of answering interrogative questions eg who what where how many when thereby making the data useful for decisions andor actionr
1107,Knowledge as synthesis of multiple sources of information over timer
1108,Eg Momentary power of solar boiler based on the rate of temperature increase of fixed volume of waterr
1109,AC compressor heater element consumes ~ even when AC is off r
1110,Laser printer occasionally using  in standby mode to warm up tonerr
1111,Dishwasher in delayed start mode consumes  till program startsr
1112,Phone uf0e0 Location detection presence detection uf0e0 Thermostatr
1113,Doorbell activation uf0e0 CCTV takes pictureuf0e0 Email  SMS  Tweetr
1114,Climate control uf0e0  presence  home & weather forecastr
1115,Hot water tank uf0df uf0e0 Hot water tank uf0df uf0e0 our presence weather forecast r
1116,Influence others to reduce their carbon footprint by sharing socially your metricsr
1117,Alex Laskey How behavioral science can lower your energy billr
1118,Ethics control society surveillance consent and data driven lifer
1119,Proprietary and incompatible protocols even from same manufacturer as part of their business modelr
1120,Data produced by the connected things is acquired processed and logged; DQ what data to collect collecting nothing with great accuracyr
1121,Run on a RO fs raspberry pi; considering moving to the cloudr
1122,As “Things become increasingly smarter they can talk directly to M layerr
1123,It is possible to have multiple interfaces on the same “Thing specializing on interfacing with certain its property AC power temperature controlr
1124,It is possible that multiple interfaced “Things have one and the same interface on the M end as long as they use same protocolr
1125,Storage Abstract and treat a  “thing with “interface EmonCMS ThingSpeak NoSQL; Retrieval of data API; r
1126,Visualization inbuilt EmonCMS Thingspeak; collect an relate data for better insight Actionable analyticsr
1127,It is an Arduinocompatible multi purpose micro that isr
1128,I’ve created a miniature Arduino compatible clone with wireless connectivity to use as interface to physical objects The project is open hardwaresourcer
1129,It is an Arduinocompatible board that acts as a wireless bridge between wireless remote nodes and the M layerr
1130,Using mosquitto MQTT broker extremely lightweight publishsubscribe messaging transport protocolr
